{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4f1d6a6",
   "metadata": {
    "id": "d4f1d6a6"
   },
   "source": [
    "Cell 1: Initial Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04cb034",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27867,
     "status": "ok",
     "timestamp": 1755496967052,
     "user": {
      "displayName": "J.",
      "userId": "08830157379463741241"
     },
     "user_tz": -480
    },
    "id": "e04cb034",
    "outputId": "86f4e24d-6dab-4e55-8802-4a2016cfc12c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "Using device: cuda\n",
      "✓ INSTANCE seismogram-based data files found\n",
      "✓ Output directory: /content/drive/My Drive/2023-2024/UCL MSc in DSML/Term 3/MSc Project/Code/INSTANCE_Seismogram_Based/experiment_results\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Lower_Half_EpiDis_INSTANCE_50_Experiments_Seismogram_Based_Splits_Runs_1_to_50.ipynb\n",
    "\n",
    "This notebook runs experiments 1 to 50 with seismogram-based random splits\n",
    "of the lower half EpiDis INSTANCE dataset for comparison with event-based splitting.\n",
    "\"\"\"\n",
    "\n",
    "# Import required libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from google.colab import drive\n",
    "import pickle\n",
    "\n",
    "# Helper function to convert numpy types to Python types for JSON serialization\n",
    "def numpy_to_python(obj):\n",
    "    \"\"\"Convert numpy types to Python types for JSON serialization.\"\"\"\n",
    "    if isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    elif isinstance(obj, np.integer):\n",
    "        return int(obj)\n",
    "    elif isinstance(obj, np.floating):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, dict):\n",
    "        return {k: numpy_to_python(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list) or isinstance(obj, tuple):\n",
    "        return [numpy_to_python(i) for i in obj]\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "# Define the range of split seeds for this notebook\n",
    "START_SEED = 1\n",
    "END_SEED = 50\n",
    "\n",
    "# Define the offset for random seeds - different from event-based to avoid overlap\n",
    "RANDOM_SEED_OFFSET = 200  # This will map split_seed 1→201, 2→202, etc.\n",
    "\n",
    "# Mount Google Drive if using Colab\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Configure environment\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# Record start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Define paths to data files (SEISMOGRAM-BASED)\n",
    "base_dir = \"/content/drive/My Drive/2023-2024/UCL MSc in DSML/Term 3/MSc Project/Code/INSTANCE_Seismogram_Based/Lower_Half_EpiDis\"\n",
    "all_data_file = os.path.join(base_dir, \"all_data.pt\")\n",
    "all_labels_file = os.path.join(base_dir, \"all_labels.pt\")\n",
    "split_info_file = os.path.join(base_dir, \"seismogram_split_info.pkl\")\n",
    "output_dir = os.path.join(base_dir, \"experiment_results\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Check if files exist\n",
    "assert os.path.isfile(all_data_file), f\"Data file not found at {all_data_file}\"\n",
    "assert os.path.isfile(all_labels_file), f\"Labels file not found at {all_labels_file}\"\n",
    "assert os.path.isfile(split_info_file), f\"Split info file not found at {split_info_file}\"\n",
    "\n",
    "print(\"✓ INSTANCE seismogram-based data files found\")\n",
    "print(f\"✓ Output directory: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be913044",
   "metadata": {
    "id": "be913044"
   },
   "source": [
    "Cell 2: Dataset and Model Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba0e9fb",
   "metadata": {
    "id": "2ba0e9fb"
   },
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------\n",
    "# Dataset and Model Classes\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "class EarthquakeDataset(Dataset):\n",
    "    \"\"\"Dataset class for earthquake data.\"\"\"\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "class EarthquakeModel(nn.Module):\n",
    "    \"\"\"MagNet architecture for earthquake magnitude estimation - ADAPTED FOR INSTANCE FORMAT.\"\"\"\n",
    "    def __init__(self):\n",
    "        super(EarthquakeModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(3, 64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(64, 32, kernel_size=3, padding=1)\n",
    "        self.maxpool = nn.MaxPool1d(4, padding=1)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.lstm = nn.LSTM(32, 100, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(200, 2)  # Output: [magnitude_prediction, log_variance]\n",
    "\n",
    "    def forward(self, x):\n",
    "        # INSTANCE data format: [batch, channels, time_steps] - NO TRANSPOSE NEEDED\n",
    "        # First conv block\n",
    "        x = self.conv1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        # Second conv block\n",
    "        x = self.conv2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        # Prepare for LSTM: [batch, time_steps, features]\n",
    "        x = x.transpose(1, 2)\n",
    "\n",
    "        # LSTM layer\n",
    "        x, _ = self.lstm(x)\n",
    "\n",
    "        # Get the last output of the LSTM\n",
    "        x = x[:, -1, :]\n",
    "\n",
    "        # Output layer with magnitude prediction and uncertainty\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b693647",
   "metadata": {
    "id": "9b693647"
   },
   "source": [
    "Cell 3: Training Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764593ee",
   "metadata": {
    "id": "764593ee"
   },
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------\n",
    "# Training Components\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stopping to prevent overfitting.\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, run_id=None,\n",
    "                 split_num=None, model_seed=None):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = float('inf')\n",
    "        self.delta = delta\n",
    "        self.run_id = run_id\n",
    "        self.split_num = split_num\n",
    "        self.model_seed = model_seed\n",
    "        self.best_model_path = None\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f})')\n",
    "        self.best_model_path = os.path.join(\n",
    "            output_dir, f'best_model_Run_{self.run_id}_split_{self.split_num}_seed_{self.model_seed}.pth'\n",
    "        )\n",
    "        torch.save(model.state_dict(), self.best_model_path)\n",
    "        self.val_loss_min = val_loss\n",
    "\n",
    "def custom_loss(y_pred, y_true):\n",
    "    \"\"\"\n",
    "    Custom loss function combining prediction error and uncertainty.\n",
    "\n",
    "    This implements a negative log-likelihood loss with learned aleatoric uncertainty:\n",
    "    L = 0.5 * exp(-s) * (y_true - y_hat)^2 + 0.5 * s\n",
    "\n",
    "    where:\n",
    "    - y_hat is the predicted magnitude\n",
    "    - s is the log variance (uncertainty)\n",
    "    - y_true is the true magnitude\n",
    "\n",
    "    This loss encourages the model to predict accurate magnitudes while\n",
    "    also learning to estimate its own uncertainty.\n",
    "    \"\"\"\n",
    "    y_hat = y_pred[:, 0]    # Predicted magnitude\n",
    "    s = y_pred[:, 1]        # Predicted log variance (uncertainty)\n",
    "\n",
    "    # Compute loss: 0.5 * exp(-s) * (y_true - y_hat)^2 + 0.5 * s\n",
    "    loss = 0.5 * torch.exp(-s) * (y_true - y_hat)**2 + 0.5 * s\n",
    "\n",
    "    return torch.mean(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484b4c61",
   "metadata": {
    "id": "484b4c61"
   },
   "source": [
    "Cell 4: Training and Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0fcd18",
   "metadata": {
    "id": "4a0fcd18"
   },
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------\n",
    "# Training and Evaluation Functions\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "def train_model(model, train_loader, val_loader, num_epochs=300, patience=5,\n",
    "                run_id=None, split_num=None, model_seed=None, verbose=False):\n",
    "    \"\"\"\n",
    "    Train the model with early stopping and learning rate scheduling.\n",
    "\n",
    "    Args:\n",
    "        model: The model to train\n",
    "        train_loader: DataLoader for training data\n",
    "        val_loader: DataLoader for validation data\n",
    "        num_epochs: Maximum number of training epochs\n",
    "        patience: Patience for early stopping\n",
    "        run_id: Identifier for the experimental run\n",
    "        split_num: Which data split is being used (0-49)\n",
    "        model_seed: Random seed used for model initialization\n",
    "        verbose: Whether to print detailed progress\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with training history and best model path\n",
    "    \"\"\"\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=np.sqrt(0.1),\n",
    "        cooldown=0, patience=4, verbose=verbose, min_lr=0.5e-6\n",
    "    )\n",
    "\n",
    "    early_stopping = EarlyStopping(\n",
    "        patience=patience, verbose=verbose,\n",
    "        run_id=run_id, split_num=split_num, model_seed=model_seed\n",
    "    )\n",
    "\n",
    "    criterion = custom_loss\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for data, target in train_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, target)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        # Validation phase\n",
    "        val_loss = 0.0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for data, target in val_loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                outputs = model(data)\n",
    "                loss = criterion(outputs, target)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        # Calculate average losses\n",
    "        val_loss /= len(val_loader)\n",
    "        running_loss /= len(train_loader)\n",
    "\n",
    "        # Learning rate scheduling and early stopping\n",
    "        scheduler.step(val_loss)\n",
    "        early_stopping(val_loss, model)\n",
    "\n",
    "        if verbose:\n",
    "            print(f'Epoch {epoch+1}, Loss: {running_loss:.4f}, '\n",
    "                  f'Validation Loss: {val_loss:.4f}, '\n",
    "                  f'LR: {optimizer.param_groups[0][\"lr\"]:.6f}')\n",
    "\n",
    "        train_losses.append(running_loss)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        if early_stopping.early_stop:\n",
    "            if verbose:\n",
    "                print(f'Early stopping triggered at epoch {epoch+1}')\n",
    "            break\n",
    "\n",
    "    return {\n",
    "        'train_losses': train_losses,\n",
    "        'val_losses': val_losses,\n",
    "        'best_model_path': early_stopping.best_model_path\n",
    "    }\n",
    "\n",
    "def estimate_uncertainty(model, data_loader, num_samples=50):\n",
    "    \"\"\"\n",
    "    Estimate model uncertainty using Monte Carlo dropout.\n",
    "\n",
    "    Args:\n",
    "        model: Trained model\n",
    "        data_loader: DataLoader for test data\n",
    "        num_samples: Number of Monte Carlo samples\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (predictions, epistemic_uncertainty, aleatoric_uncertainty, combined_uncertainty)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    # Enable dropout during inference for Monte Carlo sampling\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.Dropout):\n",
    "            m.train()\n",
    "\n",
    "    predictions = []\n",
    "    log_variances = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ in range(num_samples):\n",
    "            batch_predictions = []\n",
    "            batch_log_variances = []\n",
    "            for data, _ in data_loader:\n",
    "                data = data.to(device)\n",
    "                output = model(data)\n",
    "                batch_predictions.append(output[:, 0].cpu().numpy())\n",
    "                batch_log_variances.append(output[:, 1].cpu().numpy())\n",
    "            predictions.append(np.concatenate(batch_predictions))\n",
    "            log_variances.append(np.concatenate(batch_log_variances))\n",
    "\n",
    "    predictions = np.array(predictions)\n",
    "    log_variances = np.array(log_variances)\n",
    "\n",
    "    # Calculate mean prediction\n",
    "    mean_prediction = np.mean(predictions, axis=0)\n",
    "\n",
    "    # Calculate mean of squared predictions\n",
    "    yhat_squared_mean = np.mean(np.square(predictions), axis=0)\n",
    "\n",
    "    # Calculate aleatoric uncertainty from log variances\n",
    "    aleatoric_uncertainty = np.mean(np.exp(log_variances), axis=0)\n",
    "\n",
    "    # Calculate epistemic uncertainty as standard deviation of predictions\n",
    "    epistemic_uncertainty = np.std(predictions, axis=0)\n",
    "\n",
    "    # Calculate combined uncertainty\n",
    "    combined_uncertainty = yhat_squared_mean - np.square(mean_prediction) + aleatoric_uncertainty\n",
    "\n",
    "    return mean_prediction, epistemic_uncertainty, aleatoric_uncertainty, combined_uncertainty\n",
    "\n",
    "def evaluate_model(model_path, test_loader):\n",
    "    \"\"\"\n",
    "    Evaluate a trained model on test data.\n",
    "\n",
    "    Args:\n",
    "        model_path: Path to the saved model weights\n",
    "        test_loader: DataLoader for test data\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with evaluation metrics\n",
    "    \"\"\"\n",
    "    model = EarthquakeModel().to(device)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    # Get predictions and uncertainties\n",
    "    mean_pred, epistemic_unc, aleatoric_unc, combined_unc = estimate_uncertainty(model, test_loader)\n",
    "\n",
    "    # Get true values\n",
    "    true_values = []\n",
    "    for _, target in test_loader:\n",
    "        true_values.append(target.numpy())\n",
    "    true_values = np.concatenate(true_values)\n",
    "\n",
    "    # Calculate MAE\n",
    "    mae = np.mean(np.abs(mean_pred - true_values))\n",
    "\n",
    "    return {\n",
    "        'mae': float(mae),\n",
    "        'mean_prediction': mean_pred,\n",
    "        'true_values': true_values,\n",
    "        'epistemic_uncertainty': epistemic_unc,\n",
    "        'aleatoric_uncertainty': aleatoric_unc,\n",
    "        'combined_uncertainty': combined_unc,\n",
    "        'mean_epistemic_uncertainty': float(np.mean(epistemic_unc)),\n",
    "        'mean_aleatoric_uncertainty': float(np.mean(aleatoric_unc)),\n",
    "        'mean_combined_uncertainty': float(np.mean(combined_unc))\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe94cf4e",
   "metadata": {
    "id": "fe94cf4e"
   },
   "source": [
    "Cell 5: Experimental Functions (SEISMOGRAM-BASED SPLITTING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e2442b",
   "metadata": {
    "id": "51e2442b"
   },
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------\n",
    "# Experimental Functions (ADAPTED FOR SEISMOGRAM-BASED SPLITTING)\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "def set_seed(seed):\n",
    "    \"\"\"Set random seeds for reproducibility.\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def create_seismogram_based_split(split_seed):\n",
    "    \"\"\"\n",
    "    Create a random seismogram-based split with the specified seed\n",
    "\n",
    "    KEY DIFFERENCE: This splits seismograms randomly regardless of event membership\n",
    "\n",
    "    Args:\n",
    "        split_seed: Random seed for the split\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with train, val, test data and labels\n",
    "    \"\"\"\n",
    "    # Load the data\n",
    "    all_data = torch.load(all_data_file)\n",
    "    all_labels = torch.load(all_labels_file)\n",
    "\n",
    "    # Load the split information\n",
    "    with open(split_info_file, 'rb') as f:\n",
    "        split_info = pickle.load(f)\n",
    "\n",
    "    train_ratio = split_info['train_ratio']\n",
    "    val_ratio = split_info['val_ratio']\n",
    "    num_samples = len(all_data)\n",
    "\n",
    "    # Apply the offset to get a different random seed (201-250 instead of 1-50)\n",
    "    random_seed = split_seed + RANDOM_SEED_OFFSET\n",
    "\n",
    "    # Set the seed for reproducibility\n",
    "    print(f\"  Using random seed {random_seed} for seismogram-based split {split_seed}\")\n",
    "    set_seed(random_seed)\n",
    "\n",
    "    # Create random indices for all seismograms\n",
    "    all_indices = np.arange(num_samples)\n",
    "    np.random.shuffle(all_indices)\n",
    "\n",
    "    # Split indices randomly (KEY DIFFERENCE FROM EVENT-BASED)\n",
    "    train_size = int(train_ratio * num_samples)\n",
    "    val_size = int(val_ratio * num_samples)\n",
    "\n",
    "    train_indices = all_indices[:train_size]\n",
    "    val_indices = all_indices[train_size:train_size + val_size]\n",
    "    test_indices = all_indices[train_size + val_size:]\n",
    "\n",
    "    # Extract data using the indices\n",
    "    train_data = all_data[train_indices]\n",
    "    train_labels = all_labels[train_indices]\n",
    "\n",
    "    val_data = all_data[val_indices]\n",
    "    val_labels = all_labels[val_indices]\n",
    "\n",
    "    test_data = all_data[test_indices]\n",
    "    test_labels = all_labels[test_indices]\n",
    "\n",
    "    return {\n",
    "        'train_data': train_data,\n",
    "        'train_labels': train_labels,\n",
    "        'val_data': val_data,\n",
    "        'val_labels': val_labels,\n",
    "        'test_data': test_data,\n",
    "        'test_labels': test_labels,\n",
    "        'split_seed': split_seed,\n",
    "        'random_seed': random_seed,\n",
    "        'train_indices': train_indices,\n",
    "        'val_indices': val_indices,\n",
    "        'test_indices': test_indices,\n",
    "        'splitting_approach': 'seismogram_based'\n",
    "    }\n",
    "\n",
    "def run_experiment(split_seed, model_seeds, run_id):\n",
    "    \"\"\"\n",
    "    Run a complete experiment with multiple model initializations on a specific data split.\n",
    "\n",
    "    Args:\n",
    "        split_seed: Random seed for the split\n",
    "        model_seeds: List of random seeds for model initialization\n",
    "        run_id: Identifier for this experiment run\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with experiment results\n",
    "    \"\"\"\n",
    "    print(f\"Running seismogram-based experiment with split seed {split_seed}\")\n",
    "\n",
    "    # Create the data split (SEISMOGRAM-BASED)\n",
    "    split_data = create_seismogram_based_split(split_seed)\n",
    "\n",
    "    # Create datasets\n",
    "    train_dataset = EarthquakeDataset(split_data['train_data'], split_data['train_labels'])\n",
    "    val_dataset = EarthquakeDataset(split_data['val_data'], split_data['val_labels'])\n",
    "    test_dataset = EarthquakeDataset(split_data['test_data'], split_data['test_labels'])\n",
    "\n",
    "    # Create dataloaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True, num_workers=2)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=512, shuffle=False, num_workers=2)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=512, shuffle=False, num_workers=2)\n",
    "\n",
    "    # Log split sizes\n",
    "    print(f\"  Train: {len(train_dataset)} seismograms\")\n",
    "    print(f\"  Validation: {len(val_dataset)} seismograms\")\n",
    "    print(f\"  Test: {len(test_dataset)} seismograms\")\n",
    "    print(f\"  Note: Seismograms split randomly regardless of event membership\")\n",
    "\n",
    "    # Run experiments with multiple random initializations\n",
    "    seed_results = []\n",
    "\n",
    "    for model_seed in model_seeds:\n",
    "        print(f\"  Training with model seed {model_seed}\")\n",
    "\n",
    "        # Set random seed for model initialization\n",
    "        set_seed(model_seed)\n",
    "\n",
    "        # Initialize the model\n",
    "        model = EarthquakeModel().to(device)\n",
    "\n",
    "        # Train the model\n",
    "        training_result = train_model(\n",
    "            model, train_loader, val_loader,\n",
    "            run_id=run_id, split_num=split_seed, model_seed=model_seed,\n",
    "            verbose=False  # Set to True for detailed progress\n",
    "        )\n",
    "\n",
    "        # Evaluate the model\n",
    "        best_model_path = training_result['best_model_path']\n",
    "        evaluation_result = evaluate_model(best_model_path, test_loader)\n",
    "\n",
    "        # Store results\n",
    "        seed_results.append({\n",
    "            'model_seed': model_seed,\n",
    "            'training_history': {\n",
    "                'train_losses': training_result['train_losses'],\n",
    "                'val_losses': training_result['val_losses']\n",
    "            },\n",
    "            'evaluation': evaluation_result\n",
    "        })\n",
    "\n",
    "        print(f\"  Seed {model_seed} - MAE: {evaluation_result['mae']:.4f}\")\n",
    "\n",
    "    # Find median performance\n",
    "    sorted_results = sorted(seed_results, key=lambda x: x['evaluation']['mae'])\n",
    "    median_result = sorted_results[len(model_seeds) // 2]\n",
    "\n",
    "    return {\n",
    "        'split_seed': split_seed,\n",
    "        'random_seed_used': split_seed + RANDOM_SEED_OFFSET,\n",
    "        'splitting_approach': 'seismogram_based',\n",
    "        'all_seed_results': seed_results,\n",
    "        'median_mae': median_result['evaluation']['mae'],\n",
    "        'median_model_seed': median_result['model_seed'],\n",
    "        'median_aleatoric_uncertainty': median_result['evaluation']['mean_aleatoric_uncertainty'],\n",
    "        'median_epistemic_uncertainty': median_result['evaluation']['mean_epistemic_uncertainty'],\n",
    "        'median_combined_uncertainty': median_result['evaluation']['mean_combined_uncertainty'],\n",
    "        'train_size': len(train_dataset),\n",
    "        'val_size': len(val_dataset),\n",
    "        'test_size': len(test_dataset)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe05ebf",
   "metadata": {
    "id": "bfe05ebf"
   },
   "source": [
    "Cell 6: Main Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6dd4c77",
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "d6dd4c77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting INSTANCE Seismogram-Based Splitting Experiments 1-25\n",
      "Approach: Random seismogram splitting (potential data leakage)\n",
      "Expected: Should show BETTER performance than event-based due to data leakage\n",
      "INSTANCE (10.64 seismograms/event) vs STEAD (2.14 seismograms/event)\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rRunning experiments 1-25:   0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running seismogram-based experiment with split seed 1\n",
      "  Using random seed 101 for seismogram-based split 1\n",
      "  Train: 253563 seismograms\n",
      "  Validation: 36223 seismograms\n",
      "  Test: 72448 seismograms\n",
      "  Note: Seismograms split randomly regardless of event membership\n",
      "  Training with model seed 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Seed 42 - MAE: 0.2428\n",
      "  Training with model seed 123\n",
      "  Seed 123 - MAE: 0.1983\n",
      "  Training with model seed 256\n",
      "  Seed 256 - MAE: 0.1889\n",
      "  Training with model seed 789\n",
      "  Seed 789 - MAE: 0.1945\n",
      "  Training with model seed 1024\n",
      "  Seed 1024 - MAE: 0.1997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rRunning experiments 1-25:   4%|▍         | 1/25 [53:30<21:24:15, 3210.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed seismogram-based experiment for split seed 1 (using random seed 101)\n",
      "Median MAE: 0.1983\n",
      "Median Aleatoric Uncertainty: 0.0831\n",
      "Median Epistemic Uncertainty: 0.0704\n",
      "Median Combined Uncertainty: 0.0894\n",
      "--------------------------------------------------\n",
      "Running seismogram-based experiment with split seed 2\n",
      "  Using random seed 102 for seismogram-based split 2\n",
      "  Train: 253563 seismograms\n",
      "  Validation: 36223 seismograms\n",
      "  Test: 72448 seismograms\n",
      "  Note: Seismograms split randomly regardless of event membership\n",
      "  Training with model seed 42\n",
      "  Seed 42 - MAE: 0.1976\n",
      "  Training with model seed 123\n",
      "  Seed 123 - MAE: 0.1931\n",
      "  Training with model seed 256\n",
      "  Seed 256 - MAE: 0.2076\n",
      "  Training with model seed 789\n",
      "  Seed 789 - MAE: 0.2352\n",
      "  Training with model seed 1024\n",
      "  Seed 1024 - MAE: 0.1935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rRunning experiments 1-25:   8%|▊         | 2/25 [1:43:18<19:40:35, 3079.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed seismogram-based experiment for split seed 2 (using random seed 102)\n",
      "Median MAE: 0.1976\n",
      "Median Aleatoric Uncertainty: 0.0867\n",
      "Median Epistemic Uncertainty: 0.0667\n",
      "Median Combined Uncertainty: 0.0926\n",
      "--------------------------------------------------\n",
      "Running seismogram-based experiment with split seed 3\n",
      "  Using random seed 103 for seismogram-based split 3\n",
      "  Train: 253563 seismograms\n",
      "  Validation: 36223 seismograms\n",
      "  Test: 72448 seismograms\n",
      "  Note: Seismograms split randomly regardless of event membership\n",
      "  Training with model seed 42\n",
      "  Seed 42 - MAE: 0.2009\n",
      "  Training with model seed 123\n",
      "  Seed 123 - MAE: 0.2125\n",
      "  Training with model seed 256\n",
      "  Seed 256 - MAE: 0.2167\n",
      "  Training with model seed 789\n",
      "  Seed 789 - MAE: 0.2198\n",
      "  Training with model seed 1024\n",
      "  Seed 1024 - MAE: 0.1962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rRunning experiments 1-25:  12%|█▏        | 3/25 [2:27:27<17:37:06, 2883.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed seismogram-based experiment for split seed 3 (using random seed 103)\n",
      "Median MAE: 0.2125\n",
      "Median Aleatoric Uncertainty: 0.0996\n",
      "Median Epistemic Uncertainty: 0.0750\n",
      "Median Combined Uncertainty: 0.1069\n",
      "--------------------------------------------------\n",
      "Running seismogram-based experiment with split seed 4\n",
      "  Using random seed 104 for seismogram-based split 4\n",
      "  Train: 253563 seismograms\n",
      "  Validation: 36223 seismograms\n",
      "  Test: 72448 seismograms\n",
      "  Note: Seismograms split randomly regardless of event membership\n",
      "  Training with model seed 42\n",
      "  Seed 42 - MAE: 0.2061\n",
      "  Training with model seed 123\n",
      "  Seed 123 - MAE: 0.1809\n",
      "  Training with model seed 256\n",
      "  Seed 256 - MAE: 0.2203\n",
      "  Training with model seed 789\n",
      "  Seed 789 - MAE: 0.2031\n",
      "  Training with model seed 1024\n",
      "  Seed 1024 - MAE: 0.2042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rRunning experiments 1-25:  16%|█▌        | 4/25 [3:19:22<17:21:01, 2974.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed seismogram-based experiment for split seed 4 (using random seed 104)\n",
      "Median MAE: 0.2042\n",
      "Median Aleatoric Uncertainty: 0.0845\n",
      "Median Epistemic Uncertainty: 0.0660\n",
      "Median Combined Uncertainty: 0.0905\n",
      "--------------------------------------------------\n",
      "Running seismogram-based experiment with split seed 5\n",
      "  Using random seed 105 for seismogram-based split 5\n",
      "  Train: 253563 seismograms\n",
      "  Validation: 36223 seismograms\n",
      "  Test: 72448 seismograms\n",
      "  Note: Seismograms split randomly regardless of event membership\n",
      "  Training with model seed 42\n",
      "  Seed 42 - MAE: 0.1966\n",
      "  Training with model seed 123\n",
      "  Seed 123 - MAE: 0.2804\n",
      "  Training with model seed 256\n",
      "  Seed 256 - MAE: 0.2001\n",
      "  Training with model seed 789\n",
      "  Seed 789 - MAE: 0.2122\n",
      "  Training with model seed 1024\n",
      "  Seed 1024 - MAE: 0.2066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rRunning experiments 1-25:  20%|██        | 5/25 [4:07:52<16:23:42, 2951.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed seismogram-based experiment for split seed 5 (using random seed 105)\n",
      "Median MAE: 0.2066\n",
      "Median Aleatoric Uncertainty: 0.0908\n",
      "Median Epistemic Uncertainty: 0.0738\n",
      "Median Combined Uncertainty: 0.0980\n",
      "--------------------------------------------------\n",
      "Running seismogram-based experiment with split seed 6\n",
      "  Using random seed 106 for seismogram-based split 6\n",
      "  Train: 253563 seismograms\n",
      "  Validation: 36223 seismograms\n",
      "  Test: 72448 seismograms\n",
      "  Note: Seismograms split randomly regardless of event membership\n",
      "  Training with model seed 42\n",
      "  Seed 42 - MAE: 0.2134\n",
      "  Training with model seed 123\n",
      "  Seed 123 - MAE: 0.1978\n",
      "  Training with model seed 256\n",
      "  Seed 256 - MAE: 0.2031\n",
      "  Training with model seed 789\n",
      "  Seed 789 - MAE: 0.1996\n",
      "  Training with model seed 1024\n",
      "  Seed 1024 - MAE: 0.1968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rRunning experiments 1-25:  24%|██▍       | 6/25 [5:01:06<16:00:44, 3033.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed seismogram-based experiment for split seed 6 (using random seed 106)\n",
      "Median MAE: 0.1996\n",
      "Median Aleatoric Uncertainty: 0.0835\n",
      "Median Epistemic Uncertainty: 0.0657\n",
      "Median Combined Uncertainty: 0.0891\n",
      "--------------------------------------------------\n",
      "Running seismogram-based experiment with split seed 7\n",
      "  Using random seed 107 for seismogram-based split 7\n",
      "  Train: 253563 seismograms\n",
      "  Validation: 36223 seismograms\n",
      "  Test: 72448 seismograms\n",
      "  Note: Seismograms split randomly regardless of event membership\n",
      "  Training with model seed 42\n",
      "  Seed 42 - MAE: 0.2266\n",
      "  Training with model seed 123\n",
      "  Seed 123 - MAE: 0.2059\n",
      "  Training with model seed 256\n",
      "  Seed 256 - MAE: 0.2030\n",
      "  Training with model seed 789\n",
      "  Seed 789 - MAE: 0.2334\n",
      "  Training with model seed 1024\n",
      "  Seed 1024 - MAE: 0.1893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rRunning experiments 1-25:  28%|██▊       | 7/25 [5:45:10<14:31:52, 2906.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed seismogram-based experiment for split seed 7 (using random seed 107)\n",
      "Median MAE: 0.2059\n",
      "Median Aleatoric Uncertainty: 0.0839\n",
      "Median Epistemic Uncertainty: 0.0656\n",
      "Median Combined Uncertainty: 0.0897\n",
      "--------------------------------------------------\n",
      "Running seismogram-based experiment with split seed 8\n",
      "  Using random seed 108 for seismogram-based split 8\n",
      "  Train: 253563 seismograms\n",
      "  Validation: 36223 seismograms\n",
      "  Test: 72448 seismograms\n",
      "  Note: Seismograms split randomly regardless of event membership\n",
      "  Training with model seed 42\n",
      "  Seed 42 - MAE: 0.2292\n",
      "  Training with model seed 123\n",
      "  Seed 123 - MAE: 0.1962\n",
      "  Training with model seed 256\n",
      "  Seed 256 - MAE: 0.2081\n",
      "  Training with model seed 789\n",
      "  Seed 789 - MAE: 0.2011\n",
      "  Training with model seed 1024\n",
      "  Seed 1024 - MAE: 0.2041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rRunning experiments 1-25:  32%|███▏      | 8/25 [6:33:27<13:42:37, 2903.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed seismogram-based experiment for split seed 8 (using random seed 108)\n",
      "Median MAE: 0.2041\n",
      "Median Aleatoric Uncertainty: 0.0855\n",
      "Median Epistemic Uncertainty: 0.0646\n",
      "Median Combined Uncertainty: 0.0912\n",
      "--------------------------------------------------\n",
      "Running seismogram-based experiment with split seed 9\n",
      "  Using random seed 109 for seismogram-based split 9\n",
      "  Train: 253563 seismograms\n",
      "  Validation: 36223 seismograms\n",
      "  Test: 72448 seismograms\n",
      "  Note: Seismograms split randomly regardless of event membership\n",
      "  Training with model seed 42\n",
      "  Seed 42 - MAE: 0.2019\n",
      "  Training with model seed 123\n",
      "  Seed 123 - MAE: 0.1978\n",
      "  Training with model seed 256\n",
      "  Seed 256 - MAE: 0.1949\n",
      "  Training with model seed 789\n",
      "  Seed 789 - MAE: 0.2128\n",
      "  Training with model seed 1024\n",
      "  Seed 1024 - MAE: 0.1998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rRunning experiments 1-25:  36%|███▌      | 9/25 [7:24:24<13:07:01, 2951.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed seismogram-based experiment for split seed 9 (using random seed 109)\n",
      "Median MAE: 0.1998\n",
      "Median Aleatoric Uncertainty: 0.0853\n",
      "Median Epistemic Uncertainty: 0.0607\n",
      "Median Combined Uncertainty: 0.0901\n",
      "--------------------------------------------------\n",
      "Running seismogram-based experiment with split seed 10\n",
      "  Using random seed 110 for seismogram-based split 10\n",
      "  Train: 253563 seismograms\n",
      "  Validation: 36223 seismograms\n",
      "  Test: 72448 seismograms\n",
      "  Note: Seismograms split randomly regardless of event membership\n",
      "  Training with model seed 42\n",
      "  Seed 42 - MAE: 0.2077\n",
      "  Training with model seed 123\n",
      "  Seed 123 - MAE: 0.2016\n",
      "  Training with model seed 256\n",
      "  Seed 256 - MAE: 0.2042\n",
      "  Training with model seed 789\n",
      "  Seed 789 - MAE: 0.2180\n",
      "  Training with model seed 1024\n",
      "  Seed 1024 - MAE: 0.2208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rRunning experiments 1-25:  40%|████      | 10/25 [8:08:55<11:56:12, 2864.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed seismogram-based experiment for split seed 10 (using random seed 110)\n",
      "Median MAE: 0.2077\n",
      "Median Aleatoric Uncertainty: 0.0849\n",
      "Median Epistemic Uncertainty: 0.0631\n",
      "Median Combined Uncertainty: 0.0902\n",
      "--------------------------------------------------\n",
      "Running seismogram-based experiment with split seed 11\n",
      "  Using random seed 111 for seismogram-based split 11\n",
      "  Train: 253563 seismograms\n",
      "  Validation: 36223 seismograms\n",
      "  Test: 72448 seismograms\n",
      "  Note: Seismograms split randomly regardless of event membership\n",
      "  Training with model seed 42\n",
      "  Seed 42 - MAE: 0.2250\n",
      "  Training with model seed 123\n",
      "  Seed 123 - MAE: 0.2096\n",
      "  Training with model seed 256\n",
      "  Seed 256 - MAE: 0.2108\n",
      "  Training with model seed 789\n",
      "  Seed 789 - MAE: 0.1996\n",
      "  Training with model seed 1024\n",
      "  Seed 1024 - MAE: 0.2010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rRunning experiments 1-25:  44%|████▍     | 11/25 [8:56:18<11:06:56, 2858.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed seismogram-based experiment for split seed 11 (using random seed 111)\n",
      "Median MAE: 0.2096\n",
      "Median Aleatoric Uncertainty: 0.0784\n",
      "Median Epistemic Uncertainty: 0.0692\n",
      "Median Combined Uncertainty: 0.0849\n",
      "--------------------------------------------------\n",
      "Running seismogram-based experiment with split seed 12\n",
      "  Using random seed 112 for seismogram-based split 12\n",
      "  Train: 253563 seismograms\n",
      "  Validation: 36223 seismograms\n",
      "  Test: 72448 seismograms\n",
      "  Note: Seismograms split randomly regardless of event membership\n",
      "  Training with model seed 42\n",
      "  Seed 42 - MAE: 0.2212\n",
      "  Training with model seed 123\n",
      "  Seed 123 - MAE: 0.2056\n",
      "  Training with model seed 256\n",
      "  Seed 256 - MAE: 0.1887\n",
      "  Training with model seed 789\n",
      "  Seed 789 - MAE: 0.2001\n",
      "  Training with model seed 1024\n",
      "  Seed 1024 - MAE: 0.2121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rRunning experiments 1-25:  48%|████▊     | 12/25 [9:42:33<10:13:47, 2832.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed seismogram-based experiment for split seed 12 (using random seed 112)\n",
      "Median MAE: 0.2056\n",
      "Median Aleatoric Uncertainty: 0.0860\n",
      "Median Epistemic Uncertainty: 0.0662\n",
      "Median Combined Uncertainty: 0.0921\n",
      "--------------------------------------------------\n",
      "Running seismogram-based experiment with split seed 13\n",
      "  Using random seed 113 for seismogram-based split 13\n",
      "  Train: 253563 seismograms\n",
      "  Validation: 36223 seismograms\n",
      "  Test: 72448 seismograms\n",
      "  Note: Seismograms split randomly regardless of event membership\n",
      "  Training with model seed 42\n",
      "  Seed 42 - MAE: 0.1914\n",
      "  Training with model seed 123\n",
      "  Seed 123 - MAE: 0.2094\n",
      "  Training with model seed 256\n",
      "  Seed 256 - MAE: 0.1920\n",
      "  Training with model seed 789\n",
      "  Seed 789 - MAE: 0.2193\n",
      "  Training with model seed 1024\n",
      "  Seed 1024 - MAE: 0.1983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rRunning experiments 1-25:  52%|█████▏    | 13/25 [10:36:52<9:52:23, 2961.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed seismogram-based experiment for split seed 13 (using random seed 113)\n",
      "Median MAE: 0.1983\n",
      "Median Aleatoric Uncertainty: 0.0768\n",
      "Median Epistemic Uncertainty: 0.0616\n",
      "Median Combined Uncertainty: 0.0819\n",
      "--------------------------------------------------\n",
      "Running seismogram-based experiment with split seed 14\n",
      "  Using random seed 114 for seismogram-based split 14\n",
      "  Train: 253563 seismograms\n",
      "  Validation: 36223 seismograms\n",
      "  Test: 72448 seismograms\n",
      "  Note: Seismograms split randomly regardless of event membership\n",
      "  Training with model seed 42\n",
      "  Seed 42 - MAE: 0.2125\n",
      "  Training with model seed 123\n",
      "  Seed 123 - MAE: 0.1892\n",
      "  Training with model seed 256\n",
      "  Seed 256 - MAE: 0.2159\n",
      "  Training with model seed 789\n",
      "  Seed 789 - MAE: 0.1954\n",
      "  Training with model seed 1024\n",
      "  Seed 1024 - MAE: 0.2127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rRunning experiments 1-25:  56%|█████▌    | 14/25 [11:22:51<8:51:48, 2900.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed seismogram-based experiment for split seed 14 (using random seed 114)\n",
      "Median MAE: 0.2125\n",
      "Median Aleatoric Uncertainty: 0.0964\n",
      "Median Epistemic Uncertainty: 0.0684\n",
      "Median Combined Uncertainty: 0.1028\n",
      "--------------------------------------------------\n",
      "Running seismogram-based experiment with split seed 15\n",
      "  Using random seed 115 for seismogram-based split 15\n",
      "  Train: 253563 seismograms\n",
      "  Validation: 36223 seismograms\n",
      "  Test: 72448 seismograms\n",
      "  Note: Seismograms split randomly regardless of event membership\n",
      "  Training with model seed 42\n",
      "  Seed 42 - MAE: 0.2154\n",
      "  Training with model seed 123\n",
      "  Seed 123 - MAE: 0.1919\n",
      "  Training with model seed 256\n",
      "  Seed 256 - MAE: 0.2185\n",
      "  Training with model seed 789\n",
      "  Seed 789 - MAE: 0.2138\n",
      "  Training with model seed 1024\n",
      "  Seed 1024 - MAE: 0.2155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rRunning experiments 1-25:  60%|██████    | 15/25 [12:08:43<7:55:59, 2855.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed seismogram-based experiment for split seed 15 (using random seed 115)\n",
      "Median MAE: 0.2154\n",
      "Median Aleatoric Uncertainty: 0.0929\n",
      "Median Epistemic Uncertainty: 0.0689\n",
      "Median Combined Uncertainty: 0.0993\n",
      "--------------------------------------------------\n",
      "Running seismogram-based experiment with split seed 16\n",
      "  Using random seed 116 for seismogram-based split 16\n",
      "  Train: 253563 seismograms\n",
      "  Validation: 36223 seismograms\n",
      "  Test: 72448 seismograms\n",
      "  Note: Seismograms split randomly regardless of event membership\n",
      "  Training with model seed 42\n",
      "  Seed 42 - MAE: 0.1993\n",
      "  Training with model seed 123\n",
      "  Seed 123 - MAE: 0.2150\n",
      "  Training with model seed 256\n",
      "  Seed 256 - MAE: 0.2087\n",
      "  Training with model seed 789\n",
      "  Seed 789 - MAE: 0.1902\n",
      "  Training with model seed 1024\n",
      "  Seed 1024 - MAE: 0.2180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rRunning experiments 1-25:  64%|██████▍   | 16/25 [12:55:59<7:07:28, 2849.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed seismogram-based experiment for split seed 16 (using random seed 116)\n",
      "Median MAE: 0.2087\n",
      "Median Aleatoric Uncertainty: 0.0936\n",
      "Median Epistemic Uncertainty: 0.0715\n",
      "Median Combined Uncertainty: 0.1004\n",
      "--------------------------------------------------\n",
      "Running seismogram-based experiment with split seed 17\n",
      "  Using random seed 117 for seismogram-based split 17\n",
      "  Train: 253563 seismograms\n",
      "  Validation: 36223 seismograms\n",
      "  Test: 72448 seismograms\n",
      "  Note: Seismograms split randomly regardless of event membership\n",
      "  Training with model seed 42\n",
      "  Seed 42 - MAE: 0.2045\n",
      "  Training with model seed 123\n",
      "  Seed 123 - MAE: 0.2160\n",
      "  Training with model seed 256\n",
      "  Seed 256 - MAE: 0.2144\n",
      "  Training with model seed 789\n",
      "  Seed 789 - MAE: 0.1934\n",
      "  Training with model seed 1024\n",
      "  Seed 1024 - MAE: 0.2173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rRunning experiments 1-25:  68%|██████▊   | 17/25 [13:41:59<6:16:23, 2822.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed seismogram-based experiment for split seed 17 (using random seed 117)\n",
      "Median MAE: 0.2144\n",
      "Median Aleatoric Uncertainty: 0.0847\n",
      "Median Epistemic Uncertainty: 0.0659\n",
      "Median Combined Uncertainty: 0.0903\n",
      "--------------------------------------------------\n",
      "Running seismogram-based experiment with split seed 18\n",
      "  Using random seed 118 for seismogram-based split 18\n",
      "  Train: 253563 seismograms\n",
      "  Validation: 36223 seismograms\n",
      "  Test: 72448 seismograms\n",
      "  Note: Seismograms split randomly regardless of event membership\n",
      "  Training with model seed 42\n",
      "  Seed 42 - MAE: 0.2053\n",
      "  Training with model seed 123\n",
      "  Seed 123 - MAE: 0.3094\n",
      "  Training with model seed 256\n",
      "  Seed 256 - MAE: 0.1958\n",
      "  Training with model seed 789\n",
      "  Seed 789 - MAE: 0.2086\n",
      "  Training with model seed 1024\n",
      "  Seed 1024 - MAE: 0.2073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rRunning experiments 1-25:  72%|███████▏  | 18/25 [14:26:05<5:23:06, 2769.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed seismogram-based experiment for split seed 18 (using random seed 118)\n",
      "Median MAE: 0.2073\n",
      "Median Aleatoric Uncertainty: 0.0853\n",
      "Median Epistemic Uncertainty: 0.0704\n",
      "Median Combined Uncertainty: 0.0916\n",
      "--------------------------------------------------\n",
      "Running seismogram-based experiment with split seed 19\n",
      "  Using random seed 119 for seismogram-based split 19\n",
      "  Train: 253563 seismograms\n",
      "  Validation: 36223 seismograms\n",
      "  Test: 72448 seismograms\n",
      "  Note: Seismograms split randomly regardless of event membership\n",
      "  Training with model seed 42\n",
      "  Seed 42 - MAE: 0.2229\n",
      "  Training with model seed 123\n",
      "  Seed 123 - MAE: 0.2029\n",
      "  Training with model seed 256\n",
      "  Seed 256 - MAE: 0.2001\n",
      "  Training with model seed 789\n",
      "  Seed 789 - MAE: 0.1861\n",
      "  Training with model seed 1024\n",
      "  Seed 1024 - MAE: 0.2032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rRunning experiments 1-25:  76%|███████▌  | 19/25 [15:19:54<4:50:46, 2907.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed seismogram-based experiment for split seed 19 (using random seed 119)\n",
      "Median MAE: 0.2029\n",
      "Median Aleatoric Uncertainty: 0.0824\n",
      "Median Epistemic Uncertainty: 0.0667\n",
      "Median Combined Uncertainty: 0.0880\n",
      "--------------------------------------------------\n",
      "Running seismogram-based experiment with split seed 20\n",
      "  Using random seed 120 for seismogram-based split 20\n",
      "  Train: 253563 seismograms\n",
      "  Validation: 36223 seismograms\n",
      "  Test: 72448 seismograms\n",
      "  Note: Seismograms split randomly regardless of event membership\n",
      "  Training with model seed 42\n",
      "  Seed 42 - MAE: 0.1954\n",
      "  Training with model seed 123\n",
      "  Seed 123 - MAE: 0.1972\n",
      "  Training with model seed 256\n",
      "  Seed 256 - MAE: 0.2019\n",
      "  Training with model seed 789\n",
      "  Seed 789 - MAE: 0.2253\n",
      "  Training with model seed 1024\n",
      "  Seed 1024 - MAE: 0.2245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rRunning experiments 1-25:  80%|████████  | 20/25 [16:11:39<4:07:13, 2966.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed seismogram-based experiment for split seed 20 (using random seed 120)\n",
      "Median MAE: 0.2019\n",
      "Median Aleatoric Uncertainty: 0.0905\n",
      "Median Epistemic Uncertainty: 0.0695\n",
      "Median Combined Uncertainty: 0.0972\n",
      "--------------------------------------------------\n",
      "Running seismogram-based experiment with split seed 21\n",
      "  Using random seed 121 for seismogram-based split 21\n",
      "  Train: 253563 seismograms\n",
      "  Validation: 36223 seismograms\n",
      "  Test: 72448 seismograms\n",
      "  Note: Seismograms split randomly regardless of event membership\n",
      "  Training with model seed 42\n",
      "  Seed 42 - MAE: 0.2019\n",
      "  Training with model seed 123\n",
      "  Seed 123 - MAE: 0.2116\n",
      "  Training with model seed 256\n",
      "  Seed 256 - MAE: 0.2124\n",
      "  Training with model seed 789\n",
      "  Seed 789 - MAE: 0.2323\n",
      "  Training with model seed 1024\n",
      "  Seed 1024 - MAE: 0.2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rRunning experiments 1-25:  84%|████████▍ | 21/25 [16:58:50<3:15:04, 2926.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed seismogram-based experiment for split seed 21 (using random seed 121)\n",
      "Median MAE: 0.2116\n",
      "Median Aleatoric Uncertainty: 0.0830\n",
      "Median Epistemic Uncertainty: 0.0621\n",
      "Median Combined Uncertainty: 0.0881\n",
      "--------------------------------------------------\n",
      "Running seismogram-based experiment with split seed 22\n",
      "  Using random seed 122 for seismogram-based split 22\n",
      "  Train: 253563 seismograms\n",
      "  Validation: 36223 seismograms\n",
      "  Test: 72448 seismograms\n",
      "  Note: Seismograms split randomly regardless of event membership\n",
      "  Training with model seed 42\n",
      "  Seed 42 - MAE: 0.2014\n",
      "  Training with model seed 123\n",
      "  Seed 123 - MAE: 0.2037\n",
      "  Training with model seed 256\n",
      "  Seed 256 - MAE: 0.2139\n",
      "  Training with model seed 789\n",
      "  Seed 789 - MAE: 0.2016\n",
      "  Training with model seed 1024\n",
      "  Seed 1024 - MAE: 0.2037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rRunning experiments 1-25:  88%|████████▊ | 22/25 [17:45:54<2:24:46, 2895.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed seismogram-based experiment for split seed 22 (using random seed 122)\n",
      "Median MAE: 0.2037\n",
      "Median Aleatoric Uncertainty: 0.0903\n",
      "Median Epistemic Uncertainty: 0.0626\n",
      "Median Combined Uncertainty: 0.0956\n",
      "--------------------------------------------------\n",
      "Running seismogram-based experiment with split seed 23\n",
      "  Using random seed 123 for seismogram-based split 23\n",
      "  Train: 253563 seismograms\n",
      "  Validation: 36223 seismograms\n",
      "  Test: 72448 seismograms\n",
      "  Note: Seismograms split randomly regardless of event membership\n",
      "  Training with model seed 42\n",
      "  Seed 42 - MAE: 0.2113\n",
      "  Training with model seed 123\n",
      "  Seed 123 - MAE: 0.2120\n",
      "  Training with model seed 256\n",
      "  Seed 256 - MAE: 0.2098\n",
      "  Training with model seed 789\n",
      "  Seed 789 - MAE: 0.2115\n",
      "  Training with model seed 1024\n",
      "  Seed 1024 - MAE: 0.1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rRunning experiments 1-25:  92%|█████████▏| 23/25 [18:34:25<1:36:40, 2900.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed seismogram-based experiment for split seed 23 (using random seed 123)\n",
      "Median MAE: 0.2113\n",
      "Median Aleatoric Uncertainty: 0.0927\n",
      "Median Epistemic Uncertainty: 0.0712\n",
      "Median Combined Uncertainty: 0.0994\n",
      "--------------------------------------------------\n",
      "Running seismogram-based experiment with split seed 24\n",
      "  Using random seed 124 for seismogram-based split 24\n",
      "  Train: 253563 seismograms\n",
      "  Validation: 36223 seismograms\n",
      "  Test: 72448 seismograms\n",
      "  Note: Seismograms split randomly regardless of event membership\n",
      "  Training with model seed 42\n",
      "  Seed 42 - MAE: 0.2147\n",
      "  Training with model seed 123\n",
      "  Seed 123 - MAE: 0.2024\n",
      "  Training with model seed 256\n",
      "  Seed 256 - MAE: 0.2144\n",
      "  Training with model seed 789\n",
      "  Seed 789 - MAE: 0.2101\n",
      "  Training with model seed 1024\n",
      "  Seed 1024 - MAE: 0.1854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rRunning experiments 1-25:  96%|█████████▌| 24/25 [19:28:48<50:09, 3009.01s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed seismogram-based experiment for split seed 24 (using random seed 124)\n",
      "Median MAE: 0.2101\n",
      "Median Aleatoric Uncertainty: 0.0916\n",
      "Median Epistemic Uncertainty: 0.0726\n",
      "Median Combined Uncertainty: 0.0986\n",
      "--------------------------------------------------\n",
      "Running seismogram-based experiment with split seed 25\n",
      "  Using random seed 125 for seismogram-based split 25\n",
      "  Train: 253563 seismograms\n",
      "  Validation: 36223 seismograms\n",
      "  Test: 72448 seismograms\n",
      "  Note: Seismograms split randomly regardless of event membership\n",
      "  Training with model seed 42\n",
      "  Seed 42 - MAE: 0.2173\n",
      "  Training with model seed 123\n",
      "  Seed 123 - MAE: 0.2184\n",
      "  Training with model seed 256\n",
      "  Seed 256 - MAE: 0.2007\n",
      "  Training with model seed 789\n",
      "  Seed 789 - MAE: 0.2058\n",
      "  Training with model seed 1024\n",
      "  Seed 1024 - MAE: 0.2277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running experiments 1-25: 100%|██████████| 25/25 [20:14:47<00:00, 2915.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed seismogram-based experiment for split seed 25 (using random seed 125)\n",
      "Median MAE: 0.2173\n",
      "Median Aleatoric Uncertainty: 0.0921\n",
      "Median Epistemic Uncertainty: 0.0678\n",
      "Median Combined Uncertainty: 0.0980\n",
      "--------------------------------------------------\n",
      "\n",
      "Total execution time: 1214.82 minutes\n",
      "\n",
      "INSTANCE Seismogram-Based Experiment batch 1-25 completed!\n",
      "Results saved in: /content/drive/My Drive/2023-2024/UCL MSc in DSML/Term 3/MSc Project/Code/INSTANCE_Seismogram_Based/experiment_results/results_1_to_25.json\n",
      "\n",
      "Next steps:\n",
      "1. Run experiments 26-50\n",
      "2. Compare with event-based splitting results\n",
      "3. Analyse data leakage effects\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#------------------------------------------------------------------------------\n",
    "# Main Execution (1-50)\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Define model initialization seeds (these stay fixed across all experiments)\n",
    "    model_seeds = [42, 123, 256, 789, 1024]  # 5 different model initializations\n",
    "\n",
    "    # Define the specific split seeds for this notebook\n",
    "    split_seeds = list(range(START_SEED, END_SEED + 1))\n",
    "\n",
    "    # Define results file for this range of experiments\n",
    "    results_file = os.path.join(output_dir, f\"results_{START_SEED}_to_{END_SEED}.json\")\n",
    "\n",
    "    # Run experiments with the specified split seeds\n",
    "    all_results = []\n",
    "\n",
    "    print(f\"Starting Lower Half EpiDis INSTANCE Seismogram-Based Splitting Experiments {START_SEED}-{END_SEED}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    for i, split_seed in enumerate(tqdm(split_seeds, desc=f\"Running experiments {START_SEED}-{END_SEED}\")):\n",
    "        # Calculate the global run ID\n",
    "        global_run_id = split_seed\n",
    "\n",
    "        # Run experiment for this split\n",
    "        result = run_experiment(split_seed, model_seeds, global_run_id)\n",
    "        all_results.append(result)\n",
    "\n",
    "        # Save results after each split\n",
    "        with open(results_file, 'w') as f:\n",
    "            # Convert numpy arrays to Python lists before serialization\n",
    "            serializable_results = numpy_to_python(all_results)\n",
    "            json.dump(serializable_results, f, indent=4)\n",
    "\n",
    "        print(f\"Completed seismogram-based experiment for split seed {split_seed} (using random seed {split_seed + RANDOM_SEED_OFFSET})\")\n",
    "        print(f\"Median MAE: {result['median_mae']:.4f}\")\n",
    "        print(f\"Median Aleatoric Uncertainty: {result['median_aleatoric_uncertainty']:.4f}\")\n",
    "        print(f\"Median Epistemic Uncertainty: {result['median_epistemic_uncertainty']:.4f}\")\n",
    "        print(f\"Median Combined Uncertainty: {result['median_combined_uncertainty']:.4f}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "    # End timing\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"\\nTotal execution time: {elapsed_time/60:.2f} minutes\")\n",
    "\n",
    "    print(f\"\\nLower Half EpiDis INSTANCE Seismogram-Based Experiment batch {START_SEED}-{END_SEED} completed!\")\n",
    "    print(f\"Results saved in: {results_file}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "name": "",
   "version": ""
  },
  "kernelspec": {
   "display_name": "comp0197-cw1-pt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
