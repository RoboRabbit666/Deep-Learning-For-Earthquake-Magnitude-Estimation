{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0c94c5c",
   "metadata": {
    "id": "c0c94c5c"
   },
   "source": [
    "Cell 1: Initial Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396246e6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6273,
     "status": "ok",
     "timestamp": 1755274219094,
     "user": {
      "displayName": "J.",
      "userId": "08830157379463741241"
     },
     "user_tz": -480
    },
    "id": "396246e6",
    "outputId": "d070c65c-9588-4399-8573-38d482ad91da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "Using device: cuda\n",
      "✓ INSTANCE event-based data files found\n",
      "✓ Output directory: /content/drive/My Drive/2023-2024/UCL MSc in DSML/Term 3/MSc Project/Code/INSTANCE_Event_Based/experiment_results\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"INSTANCE_50_Experiments_Event_Based_Splits_Runs_1_to_50.ipynb\n",
    "\n",
    "This notebook runs experiments 1 to 50 with different event-based random splits\n",
    "of the lower half Epicenter Distance INSTANCE dataset.\n",
    "\"\"\"\n",
    "\n",
    "# Import required libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from google.colab import drive\n",
    "import pickle\n",
    "\n",
    "# Helper function to convert numpy types to Python types for JSON serialization\n",
    "def numpy_to_python(obj):\n",
    "    \"\"\"Convert numpy types to Python types for JSON serialization.\"\"\"\n",
    "    if isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    elif isinstance(obj, np.integer):\n",
    "        return int(obj)\n",
    "    elif isinstance(obj, np.floating):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, dict):\n",
    "        return {k: numpy_to_python(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list) or isinstance(obj, tuple):\n",
    "        return [numpy_to_python(i) for i in obj]\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "# Define the range of split seeds for this notebook\n",
    "START_SEED = 1\n",
    "END_SEED = 50\n",
    "\n",
    "# Define the offset for random seeds to avoid overlap with seismogram-based split seeds\n",
    "RANDOM_SEED_OFFSET = 400  # This will map split_seed 1→401, 2→402, etc.\n",
    "\n",
    "# Mount Google Drive if using Colab\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Configure environment\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# Record start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Define paths to data files (UPDATED FOR INSTANCE)\n",
    "base_dir = \"/content/drive/My Drive/2023-2024/UCL MSc in DSML/Term 3/MSc Project/Code/INSTANCE_Event_Based/Lower_Half_EpiDis\"\n",
    "all_data_file = os.path.join(base_dir, \"all_data.pt\")\n",
    "all_labels_file = os.path.join(base_dir, \"all_labels.pt\")\n",
    "split_info_file = os.path.join(base_dir, \"event_split_info.pkl\")\n",
    "output_dir = os.path.join(base_dir, \"experiment_results\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Check if files exist\n",
    "assert os.path.isfile(all_data_file), f\"Data file not found at {all_data_file}\"\n",
    "assert os.path.isfile(all_labels_file), f\"Labels file not found at {all_labels_file}\"\n",
    "assert os.path.isfile(split_info_file), f\"Split info file not found at {split_info_file}\"\n",
    "\n",
    "print(\"✓ INSTANCE event-based data files found\")\n",
    "print(f\"✓ Output directory: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e50a67",
   "metadata": {
    "id": "a2e50a67"
   },
   "source": [
    "Cell 2: Dataset and Model Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50ace4f",
   "metadata": {
    "id": "c50ace4f"
   },
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------\n",
    "# Dataset and Model Classes (FIXED FOR INSTANCE DATA FORMAT)\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "class EarthquakeDataset(Dataset):\n",
    "    \"\"\"Dataset class for earthquake data.\"\"\"\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "class EarthquakeModel(nn.Module):\n",
    "    \"\"\"MagNet architecture for earthquake magnitude estimation - ADAPTED FOR INSTANCE FORMAT.\"\"\"\n",
    "    def __init__(self):\n",
    "        super(EarthquakeModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(3, 64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(64, 32, kernel_size=3, padding=1)\n",
    "        self.maxpool = nn.MaxPool1d(4, padding=1)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.lstm = nn.LSTM(32, 100, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(200, 2)  # Output: [magnitude_prediction, log_variance]\n",
    "\n",
    "    def forward(self, x):\n",
    "        # INSTANCE data format: [batch, channels, time_steps] - NO TRANSPOSE NEEDED\n",
    "        # STEAD data format would be: [batch, time_steps, channels] - would need transpose\n",
    "\n",
    "        # Check input shape and print for debugging\n",
    "        # print(f\"Input shape: {x.shape}\")  # The input format should be [batch, channels, time_steps] which would be (batch_size, 3, 3000)\n",
    "\n",
    "        # For INSTANCE: x is already [batch, channels, time_steps], so use directly\n",
    "        # For STEAD: x would be [batch, time_steps, channels], so would need: x = x.transpose(1, 2)\n",
    "\n",
    "        # Since INSTANCE data is (362234, 3, 3000), each batch will be [batch, 3, 3000]\n",
    "        # which is exactly what Conv1d expects: [batch, channels, time_steps]\n",
    "\n",
    "        # First conv block\n",
    "        x = self.conv1(x)  # Input: [batch, 3, 3000] -> Output: [batch, 64, 3000]\n",
    "        x = self.dropout(x)\n",
    "        x = self.maxpool(x)  # Output: [batch, 64, 750]\n",
    "\n",
    "        # Second conv block\n",
    "        x = self.conv2(x)  # Input: [batch, 64, 750] -> Output: [batch, 32, 750]\n",
    "        x = self.dropout(x)\n",
    "        x = self.maxpool(x)  # Output: [batch, 32, 187]\n",
    "\n",
    "        # Prepare for LSTM: [batch, time_steps, features]\n",
    "        x = x.transpose(1, 2)  # [batch, 32, 187] -> [batch, 187, 32]\n",
    "\n",
    "        # LSTM layer\n",
    "        x, _ = self.lstm(x)  # Input: [batch, 187, 32] -> Output: [batch, 187, 200]\n",
    "\n",
    "        # Get the last output of the LSTM\n",
    "        x = x[:, -1, :]  # [batch, 187, 200] -> [batch, 200]\n",
    "\n",
    "        # Output layer with magnitude prediction and uncertainty\n",
    "        x = self.fc(x)  # [batch, 200] -> [batch, 2]\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d680806a",
   "metadata": {
    "id": "d680806a"
   },
   "source": [
    "Cell 3: Training Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a984fb",
   "metadata": {
    "id": "39a984fb"
   },
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------\n",
    "# Training Components\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stopping to prevent overfitting.\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, run_id=None,\n",
    "                 split_num=None, model_seed=None):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = float('inf')\n",
    "        self.delta = delta\n",
    "        self.run_id = run_id\n",
    "        self.split_num = split_num\n",
    "        self.model_seed = model_seed\n",
    "        self.best_model_path = None\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f})')\n",
    "        self.best_model_path = os.path.join(\n",
    "            output_dir, f'best_model_Run_{self.run_id}_split_{self.split_num}_seed_{self.model_seed}.pth'\n",
    "        )\n",
    "        torch.save(model.state_dict(), self.best_model_path)\n",
    "        self.val_loss_min = val_loss\n",
    "\n",
    "def custom_loss(y_pred, y_true):\n",
    "    \"\"\"\n",
    "    Custom loss function combining prediction error and uncertainty.\n",
    "\n",
    "    This implements a negative log-likelihood loss with learned aleatoric uncertainty:\n",
    "    L = 0.5 * exp(-s) * (y_true - y_hat)^2 + 0.5 * s\n",
    "\n",
    "    where:\n",
    "    - y_hat is the predicted magnitude\n",
    "    - s is the log variance (uncertainty)\n",
    "    - y_true is the true magnitude\n",
    "\n",
    "    This loss encourages the model to predict accurate magnitudes while\n",
    "    also learning to estimate its own uncertainty.\n",
    "    \"\"\"\n",
    "    y_hat = y_pred[:, 0]    # Predicted magnitude\n",
    "    s = y_pred[:, 1]        # Predicted log variance (uncertainty)\n",
    "\n",
    "    # Compute loss: 0.5 * exp(-s) * (y_true - y_hat)^2 + 0.5 * s\n",
    "    loss = 0.5 * torch.exp(-s) * (y_true - y_hat)**2 + 0.5 * s\n",
    "\n",
    "    return torch.mean(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec50d484",
   "metadata": {
    "id": "ec50d484"
   },
   "source": [
    "Cell 4: Training and Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0dac5e",
   "metadata": {
    "id": "ad0dac5e"
   },
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------\n",
    "# Training and Evaluation Functions\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "def train_model(model, train_loader, val_loader, num_epochs=300, patience=5,\n",
    "                run_id=None, split_num=None, model_seed=None, verbose=False):\n",
    "    \"\"\"\n",
    "    Train the model with early stopping and learning rate scheduling.\n",
    "\n",
    "    Args:\n",
    "        model: The model to train\n",
    "        train_loader: DataLoader for training data\n",
    "        val_loader: DataLoader for validation data\n",
    "        num_epochs: Maximum number of training epochs\n",
    "        patience: Patience for early stopping\n",
    "        run_id: Identifier for the experimental run\n",
    "        split_num: Which data split is being used (0-49)\n",
    "        model_seed: Random seed used for model initialization\n",
    "        verbose: Whether to print detailed progress\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with training history and best model path\n",
    "    \"\"\"\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=np.sqrt(0.1),\n",
    "        cooldown=0, patience=4, min_lr=0.5e-6\n",
    "    )\n",
    "\n",
    "    early_stopping = EarlyStopping(\n",
    "        patience=patience, verbose=verbose,\n",
    "        run_id=run_id, split_num=split_num, model_seed=model_seed\n",
    "    )\n",
    "\n",
    "    criterion = custom_loss\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for data, target in train_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, target)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        # Validation phase\n",
    "        val_loss = 0.0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for data, target in val_loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                outputs = model(data)\n",
    "                loss = criterion(outputs, target)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        # Calculate average losses\n",
    "        val_loss /= len(val_loader)\n",
    "        running_loss /= len(train_loader)\n",
    "\n",
    "        # Learning rate scheduling and early stopping\n",
    "        scheduler.step(val_loss)\n",
    "        early_stopping(val_loss, model)\n",
    "\n",
    "        if verbose:\n",
    "            print(f'Epoch {epoch+1}, Loss: {running_loss:.4f}, '\n",
    "                  f'Validation Loss: {val_loss:.4f}, '\n",
    "                  f'LR: {optimizer.param_groups[0][\"lr\"]:.6f}')\n",
    "\n",
    "        train_losses.append(running_loss)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        if early_stopping.early_stop:\n",
    "            if verbose:\n",
    "                print(f'Early stopping triggered at epoch {epoch+1}')\n",
    "            break\n",
    "\n",
    "    return {\n",
    "        'train_losses': train_losses,\n",
    "        'val_losses': val_losses,\n",
    "        'best_model_path': early_stopping.best_model_path\n",
    "    }\n",
    "\n",
    "def estimate_uncertainty(model, data_loader, num_samples=50):\n",
    "    \"\"\"\n",
    "    Estimate model uncertainty using Monte Carlo dropout.\n",
    "\n",
    "    Args:\n",
    "        model: Trained model\n",
    "        data_loader: DataLoader for test data\n",
    "        num_samples: Number of Monte Carlo samples\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (predictions, epistemic_uncertainty, aleatoric_uncertainty, combined_uncertainty)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    # Enable dropout during inference for Monte Carlo sampling\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.Dropout):\n",
    "            m.train()\n",
    "\n",
    "    predictions = []\n",
    "    log_variances = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ in range(num_samples):\n",
    "            batch_predictions = []\n",
    "            batch_log_variances = []\n",
    "            for data, _ in data_loader:\n",
    "                data = data.to(device)\n",
    "                output = model(data)\n",
    "                batch_predictions.append(output[:, 0].cpu().numpy())\n",
    "                batch_log_variances.append(output[:, 1].cpu().numpy())\n",
    "            predictions.append(np.concatenate(batch_predictions))\n",
    "            log_variances.append(np.concatenate(batch_log_variances))\n",
    "\n",
    "    predictions = np.array(predictions)\n",
    "    log_variances = np.array(log_variances)\n",
    "\n",
    "    # Calculate mean prediction\n",
    "    mean_prediction = np.mean(predictions, axis=0)\n",
    "\n",
    "    # Calculate mean of squared predictions\n",
    "    yhat_squared_mean = np.mean(np.square(predictions), axis=0)\n",
    "\n",
    "    # Calculate aleatoric uncertainty from log variances\n",
    "    aleatoric_uncertainty = np.mean(np.exp(log_variances), axis=0)\n",
    "\n",
    "    # Calculate epistemic uncertainty as standard deviation of predictions\n",
    "    epistemic_uncertainty = np.std(predictions, axis=0)\n",
    "\n",
    "    # Calculate combined uncertainty\n",
    "    combined_uncertainty = yhat_squared_mean - np.square(mean_prediction) + aleatoric_uncertainty\n",
    "\n",
    "    return mean_prediction, epistemic_uncertainty, aleatoric_uncertainty, combined_uncertainty\n",
    "\n",
    "def evaluate_model(model_path, test_loader):\n",
    "    \"\"\"\n",
    "    Evaluate a trained model on test data.\n",
    "\n",
    "    Args:\n",
    "        model_path: Path to the saved model weights\n",
    "        test_loader: DataLoader for test data\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with evaluation metrics\n",
    "    \"\"\"\n",
    "    model = EarthquakeModel().to(device)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    # Get predictions and uncertainties\n",
    "    mean_pred, epistemic_unc, aleatoric_unc, combined_unc = estimate_uncertainty(model, test_loader)\n",
    "\n",
    "    # Get true values\n",
    "    true_values = []\n",
    "    for _, target in test_loader:\n",
    "        true_values.append(target.numpy())\n",
    "    true_values = np.concatenate(true_values)\n",
    "\n",
    "    # Calculate MAE\n",
    "    mae = np.mean(np.abs(mean_pred - true_values))\n",
    "\n",
    "    return {\n",
    "        'mae': float(mae),\n",
    "        'mean_prediction': mean_pred,\n",
    "        'true_values': true_values,\n",
    "        'epistemic_uncertainty': epistemic_unc,\n",
    "        'aleatoric_uncertainty': aleatoric_unc,\n",
    "        'combined_uncertainty': combined_unc,\n",
    "        'mean_epistemic_uncertainty': float(np.mean(epistemic_unc)),\n",
    "        'mean_aleatoric_uncertainty': float(np.mean(aleatoric_unc)),\n",
    "        'mean_combined_uncertainty': float(np.mean(combined_unc))\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ad80fe",
   "metadata": {
    "id": "e5ad80fe"
   },
   "source": [
    "Cell 5: Experimental Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248d91f5",
   "metadata": {
    "id": "248d91f5"
   },
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------\n",
    "# Experimental Functions\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "def set_seed(seed):\n",
    "    \"\"\"Set random seeds for reproducibility.\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def create_event_based_split(split_seed):\n",
    "    \"\"\"\n",
    "    Create a random event-based split with the specified seed\n",
    "\n",
    "    Args:\n",
    "        split_seed: Random seed for the split\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with train, val, test data and labels\n",
    "    \"\"\"\n",
    "    # Load the data\n",
    "    all_data = torch.load(all_data_file)\n",
    "    all_labels = torch.load(all_labels_file)\n",
    "\n",
    "    # Load the split information\n",
    "    with open(split_info_file, 'rb') as f:\n",
    "        split_info = pickle.load(f)\n",
    "\n",
    "    unique_events = split_info['unique_events']\n",
    "    event_indices = split_info['event_indices']\n",
    "    train_ratio = split_info['train_ratio']\n",
    "    val_ratio = split_info['val_ratio']\n",
    "\n",
    "    # Apply the offset to get a different random seed (401-450)\n",
    "    random_seed = split_seed + RANDOM_SEED_OFFSET\n",
    "\n",
    "    # Set the seed for reproducibility using the new random seed\n",
    "    print(f\"  Using random seed {random_seed} for split {split_seed}\")\n",
    "    set_seed(random_seed)\n",
    "\n",
    "    # Create a shuffled copy of the unique events\n",
    "    events_copy = unique_events.copy()\n",
    "    random.shuffle(events_copy)\n",
    "\n",
    "    # Split events into train/val/test\n",
    "    train_size = int(train_ratio * len(events_copy))\n",
    "    val_size = int(val_ratio * len(events_copy))\n",
    "\n",
    "    train_events = events_copy[:train_size]\n",
    "    val_events = events_copy[train_size:train_size + val_size]\n",
    "    test_events = events_copy[train_size + val_size:]\n",
    "\n",
    "    # Collect indices for each split\n",
    "    train_indices = np.concatenate([event_indices[event_id] for event_id in train_events])\n",
    "    val_indices = np.concatenate([event_indices[event_id] for event_id in val_events])\n",
    "    test_indices = np.concatenate([event_indices[event_id] for event_id in test_events])\n",
    "\n",
    "    # Extract data using the indices\n",
    "    train_data = all_data[train_indices]\n",
    "    train_labels = all_labels[train_indices]\n",
    "\n",
    "    val_data = all_data[val_indices]\n",
    "    val_labels = all_labels[val_indices]\n",
    "\n",
    "    test_data = all_data[test_indices]\n",
    "    test_labels = all_labels[test_indices]\n",
    "\n",
    "    return {\n",
    "        'train_data': train_data,\n",
    "        'train_labels': train_labels,\n",
    "        'val_data': val_data,\n",
    "        'val_labels': val_labels,\n",
    "        'test_data': test_data,\n",
    "        'test_labels': test_labels,\n",
    "        'split_seed': split_seed,  # Keep the original split_seed for labeling (1-25)\n",
    "        'random_seed': random_seed,  # Save the actual random seed used (51-75)\n",
    "        'train_events': train_events,\n",
    "        'val_events': val_events,\n",
    "        'test_events': test_events\n",
    "    }\n",
    "\n",
    "def run_experiment(split_seed, model_seeds, run_id):\n",
    "    \"\"\"\n",
    "    Run a complete experiment with multiple model initializations on a specific data split.\n",
    "\n",
    "    Args:\n",
    "        split_seed: Random seed for the split\n",
    "        model_seeds: List of random seeds for model initialization\n",
    "        run_id: Identifier for this experiment run\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with experiment results\n",
    "    \"\"\"\n",
    "    print(f\"Running experiment with split seed {split_seed}\")\n",
    "\n",
    "    # Create the data split\n",
    "    split_data = create_event_based_split(split_seed)\n",
    "\n",
    "    # Create datasets\n",
    "    train_dataset = EarthquakeDataset(split_data['train_data'], split_data['train_labels'])\n",
    "    val_dataset = EarthquakeDataset(split_data['val_data'], split_data['val_labels'])\n",
    "    test_dataset = EarthquakeDataset(split_data['test_data'], split_data['test_labels'])\n",
    "\n",
    "    # Create dataloaders (UPDATED BATCH SIZE FOR LARGER INSTANCE DATASET)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True, num_workers=2)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=512, shuffle=False, num_workers=2)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=512, shuffle=False, num_workers=2)\n",
    "\n",
    "    # Log split sizes\n",
    "    print(f\"  Train: {len(train_dataset)} samples from {len(split_data['train_events'])} events\")\n",
    "    print(f\"  Validation: {len(val_dataset)} samples from {len(split_data['val_events'])} events\")\n",
    "    print(f\"  Test: {len(test_dataset)} samples from {len(split_data['test_events'])} events\")\n",
    "\n",
    "    # Run experiments with multiple random initializations\n",
    "    seed_results = []\n",
    "\n",
    "    for model_seed in model_seeds:\n",
    "        print(f\"  Training with model seed {model_seed}\")\n",
    "\n",
    "        # Set random seed for model initialization\n",
    "        set_seed(model_seed)\n",
    "\n",
    "        # Initialize the model\n",
    "        model = EarthquakeModel().to(device)\n",
    "\n",
    "        # Train the model\n",
    "        training_result = train_model(\n",
    "            model, train_loader, val_loader,\n",
    "            run_id=run_id, split_num=split_seed, model_seed=model_seed,\n",
    "            verbose=False  # Set to True for detailed progress\n",
    "        )\n",
    "\n",
    "        # Evaluate the model\n",
    "        best_model_path = training_result['best_model_path']\n",
    "        evaluation_result = evaluate_model(best_model_path, test_loader)\n",
    "\n",
    "        # Store results\n",
    "        seed_results.append({\n",
    "            'model_seed': model_seed,\n",
    "            'training_history': {\n",
    "                'train_losses': training_result['train_losses'],\n",
    "                'val_losses': training_result['val_losses']\n",
    "            },\n",
    "            'evaluation': evaluation_result\n",
    "        })\n",
    "\n",
    "        print(f\"  Seed {model_seed} - MAE: {evaluation_result['mae']:.4f}\")\n",
    "\n",
    "    # Find median performance\n",
    "    sorted_results = sorted(seed_results, key=lambda x: x['evaluation']['mae'])\n",
    "    median_result = sorted_results[len(model_seeds) // 2]\n",
    "\n",
    "    return {\n",
    "        'split_seed': split_seed,\n",
    "        'random_seed_used': split_seed + RANDOM_SEED_OFFSET,  # Save the actual random seed used\n",
    "        'all_seed_results': seed_results,\n",
    "        'median_mae': median_result['evaluation']['mae'],\n",
    "        'median_model_seed': median_result['model_seed'],\n",
    "        'median_aleatoric_uncertainty': median_result['evaluation']['mean_aleatoric_uncertainty'],\n",
    "        'median_epistemic_uncertainty': median_result['evaluation']['mean_epistemic_uncertainty'],\n",
    "        'median_combined_uncertainty': median_result['evaluation']['mean_combined_uncertainty'],\n",
    "        'train_size': len(train_dataset),\n",
    "        'val_size': len(val_dataset),\n",
    "        'test_size': len(test_dataset),\n",
    "        'train_events': len(split_data['train_events']),\n",
    "        'val_events': len(split_data['val_events']),\n",
    "        'test_events': len(split_data['test_events'])\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d76e514",
   "metadata": {
    "id": "2d76e514"
   },
   "source": [
    "Cell 6: Main Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d276a9",
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "30d276a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting INSTANCE Event-Based Splitting Experiments 1-25\n",
      "Expected: INSTANCE (avg 10.64 seismograms/event) should show MORE pronounced\n",
      "differences than STEAD (avg 2.14 seismograms/event) between splitting methods\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rRunning experiments 1-25:   0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment with split seed 1\n",
      "  Using random seed 51 for split 1\n",
      "  Train: 253575 samples from 23821 events\n",
      "  Validation: 37162 samples from 3403 events\n",
      "  Test: 71497 samples from 6807 events\n",
      "  Training with model seed 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Seed 42 - MAE: 0.2196\n",
      "  Training with model seed 123\n",
      "  Seed 123 - MAE: 0.2041\n",
      "  Training with model seed 256\n",
      "  Seed 256 - MAE: 0.2151\n",
      "  Training with model seed 789\n",
      "  Seed 789 - MAE: 0.2129\n",
      "  Training with model seed 1024\n",
      "  Seed 1024 - MAE: 0.2183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rRunning experiments 1-25:   4%|▍         | 1/25 [37:58<15:11:18, 2278.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed experiment for split seed 1 (using random seed 51)\n",
      "Median MAE: 0.2151\n",
      "Median Aleatoric Uncertainty: 0.1020\n",
      "Median Epistemic Uncertainty: 0.0722\n",
      "Median Combined Uncertainty: 0.1090\n",
      "--------------------------------------------------\n",
      "Running experiment with split seed 2\n",
      "  Using random seed 52 for split 2\n",
      "  Train: 254042 samples from 23821 events\n",
      "  Validation: 34667 samples from 3403 events\n",
      "  Test: 73525 samples from 6807 events\n",
      "  Training with model seed 42\n",
      "  Seed 42 - MAE: 0.2122\n",
      "  Training with model seed 123\n",
      "  Seed 123 - MAE: 0.2005\n",
      "  Training with model seed 256\n",
      "  Seed 256 - MAE: 0.1972\n",
      "  Training with model seed 789\n",
      "  Seed 789 - MAE: 0.2088\n",
      "  Training with model seed 1024\n",
      "  Seed 1024 - MAE: 0.2108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rRunning experiments 1-25:   8%|▊         | 2/25 [1:25:27<16:41:59, 2613.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed experiment for split seed 2 (using random seed 52)\n",
      "Median MAE: 0.2088\n",
      "Median Aleatoric Uncertainty: 0.1011\n",
      "Median Epistemic Uncertainty: 0.0668\n",
      "Median Combined Uncertainty: 0.1070\n",
      "--------------------------------------------------\n",
      "Running experiment with split seed 3\n",
      "  Using random seed 53 for split 3\n",
      "  Train: 251063 samples from 23821 events\n",
      "  Validation: 37801 samples from 3403 events\n",
      "  Test: 73370 samples from 6807 events\n",
      "  Training with model seed 42\n",
      "  Seed 42 - MAE: 0.2029\n",
      "  Training with model seed 123\n",
      "  Seed 123 - MAE: 0.1832\n",
      "  Training with model seed 256\n",
      "  Seed 256 - MAE: 0.2285\n",
      "  Training with model seed 789\n",
      "  Seed 789 - MAE: 0.2120\n",
      "  Training with model seed 1024\n",
      "  Seed 1024 - MAE: 0.2119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rRunning experiments 1-25:  12%|█▏        | 3/25 [2:12:50<16:36:52, 2718.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed experiment for split seed 3 (using random seed 53)\n",
      "Median MAE: 0.2119\n",
      "Median Aleatoric Uncertainty: 0.0941\n",
      "Median Epistemic Uncertainty: 0.0691\n",
      "Median Combined Uncertainty: 0.1005\n",
      "--------------------------------------------------\n",
      "Running experiment with split seed 4\n",
      "  Using random seed 54 for split 4\n",
      "  Train: 253495 samples from 23821 events\n",
      "  Validation: 35813 samples from 3403 events\n",
      "  Test: 72926 samples from 6807 events\n",
      "  Training with model seed 42\n",
      "  Seed 42 - MAE: 0.1859\n",
      "  Training with model seed 123\n",
      "  Seed 123 - MAE: 0.2109\n",
      "  Training with model seed 256\n",
      "  Seed 256 - MAE: 0.2044\n",
      "  Training with model seed 789\n",
      "  Seed 789 - MAE: 0.2066\n",
      "  Training with model seed 1024\n",
      "  Seed 1024 - MAE: 0.2243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rRunning experiments 1-25:  16%|█▌        | 4/25 [3:03:51<16:38:54, 2854.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed experiment for split seed 4 (using random seed 54)\n",
      "Median MAE: 0.2066\n",
      "Median Aleatoric Uncertainty: 0.0883\n",
      "Median Epistemic Uncertainty: 0.0688\n",
      "Median Combined Uncertainty: 0.0952\n",
      "--------------------------------------------------\n",
      "Running experiment with split seed 5\n",
      "  Using random seed 55 for split 5\n",
      "  Train: 254366 samples from 23821 events\n",
      "  Validation: 36752 samples from 3403 events\n",
      "  Test: 71116 samples from 6807 events\n",
      "  Training with model seed 42\n",
      "  Seed 42 - MAE: 0.2133\n",
      "  Training with model seed 123\n",
      "  Seed 123 - MAE: 0.1896\n",
      "  Training with model seed 256\n",
      "  Seed 256 - MAE: 0.2088\n",
      "  Training with model seed 789\n",
      "  Seed 789 - MAE: 0.2101\n",
      "  Training with model seed 1024\n",
      "  Seed 1024 - MAE: 0.1968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rRunning experiments 1-25:  20%|██        | 5/25 [3:59:26<16:49:03, 3027.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed experiment for split seed 5 (using random seed 55)\n",
      "Median MAE: 0.2088\n",
      "Median Aleatoric Uncertainty: 0.0857\n",
      "Median Epistemic Uncertainty: 0.0613\n",
      "Median Combined Uncertainty: 0.0907\n",
      "--------------------------------------------------\n",
      "Running experiment with split seed 6\n",
      "  Using random seed 56 for split 6\n",
      "  Train: 253379 samples from 23821 events\n",
      "  Validation: 37323 samples from 3403 events\n",
      "  Test: 71532 samples from 6807 events\n",
      "  Training with model seed 42\n",
      "  Seed 42 - MAE: 0.2162\n",
      "  Training with model seed 123\n",
      "  Seed 123 - MAE: 0.2001\n",
      "  Training with model seed 256\n",
      "  Seed 256 - MAE: 0.2285\n",
      "  Training with model seed 789\n",
      "  Seed 789 - MAE: 0.2005\n",
      "  Training with model seed 1024\n",
      "  Seed 1024 - MAE: 0.2076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rRunning experiments 1-25:  24%|██▍       | 6/25 [4:47:57<15:46:06, 2987.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed experiment for split seed 6 (using random seed 56)\n",
      "Median MAE: 0.2076\n",
      "Median Aleatoric Uncertainty: 0.0832\n",
      "Median Epistemic Uncertainty: 0.0604\n",
      "Median Combined Uncertainty: 0.0881\n",
      "--------------------------------------------------\n",
      "Running experiment with split seed 7\n",
      "  Using random seed 57 for split 7\n",
      "  Train: 254797 samples from 23821 events\n",
      "  Validation: 36299 samples from 3403 events\n",
      "  Test: 71138 samples from 6807 events\n",
      "  Training with model seed 42\n",
      "  Seed 42 - MAE: 0.2316\n",
      "  Training with model seed 123\n",
      "  Seed 123 - MAE: 0.2278\n",
      "  Training with model seed 256\n",
      "  Seed 256 - MAE: 0.2156\n",
      "  Training with model seed 789\n",
      "  Seed 789 - MAE: 0.1883\n",
      "  Training with model seed 1024\n",
      "  Seed 1024 - MAE: 0.2046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rRunning experiments 1-25:  28%|██▊       | 7/25 [5:29:44<14:09:10, 2830.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed experiment for split seed 7 (using random seed 57)\n",
      "Median MAE: 0.2156\n",
      "Median Aleatoric Uncertainty: 0.0926\n",
      "Median Epistemic Uncertainty: 0.0721\n",
      "Median Combined Uncertainty: 0.0996\n",
      "--------------------------------------------------\n",
      "Running experiment with split seed 8\n",
      "  Using random seed 58 for split 8\n",
      "  Train: 253160 samples from 23821 events\n",
      "  Validation: 35485 samples from 3403 events\n",
      "  Test: 73589 samples from 6807 events\n",
      "  Training with model seed 42\n",
      "  Seed 42 - MAE: 0.1976\n",
      "  Training with model seed 123\n",
      "  Seed 123 - MAE: 0.1911\n",
      "  Training with model seed 256\n",
      "  Seed 256 - MAE: 0.1981\n",
      "  Training with model seed 789\n",
      "  Seed 789 - MAE: 0.2037\n",
      "  Training with model seed 1024\n",
      "  Seed 1024 - MAE: 0.2169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rRunning experiments 1-25:  32%|███▏      | 8/25 [6:19:09<13:34:07, 2873.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed experiment for split seed 8 (using random seed 58)\n",
      "Median MAE: 0.1981\n",
      "Median Aleatoric Uncertainty: 0.0938\n",
      "Median Epistemic Uncertainty: 0.0625\n",
      "Median Combined Uncertainty: 0.0992\n",
      "--------------------------------------------------\n",
      "Running experiment with split seed 9\n",
      "  Using random seed 59 for split 9\n",
      "  Train: 252380 samples from 23821 events\n",
      "  Validation: 36590 samples from 3403 events\n",
      "  Test: 73264 samples from 6807 events\n",
      "  Training with model seed 42\n",
      "  Seed 42 - MAE: 0.1902\n",
      "  Training with model seed 123\n",
      "  Seed 123 - MAE: 0.1921\n",
      "  Training with model seed 256\n",
      "  Seed 256 - MAE: 0.2572\n",
      "  Training with model seed 789\n",
      "  Seed 789 - MAE: 0.2102\n",
      "  Training with model seed 1024\n",
      "  Seed 1024 - MAE: 0.2214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rRunning experiments 1-25:  36%|███▌      | 9/25 [7:10:52<13:05:23, 2945.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed experiment for split seed 9 (using random seed 59)\n",
      "Median MAE: 0.2102\n",
      "Median Aleatoric Uncertainty: 0.0886\n",
      "Median Epistemic Uncertainty: 0.0684\n",
      "Median Combined Uncertainty: 0.0953\n",
      "--------------------------------------------------\n",
      "Running experiment with split seed 10\n",
      "  Using random seed 60 for split 10\n",
      "  Train: 256601 samples from 23821 events\n",
      "  Validation: 35633 samples from 3403 events\n",
      "  Test: 70000 samples from 6807 events\n",
      "  Training with model seed 42\n",
      "  Seed 42 - MAE: 0.2282\n",
      "  Training with model seed 123\n",
      "  Seed 123 - MAE: 0.1887\n",
      "  Training with model seed 256\n",
      "  Seed 256 - MAE: 0.2106\n",
      "  Training with model seed 789\n",
      "  Seed 789 - MAE: 0.2042\n",
      "  Training with model seed 1024\n",
      "  Seed 1024 - MAE: 0.1872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rRunning experiments 1-25:  40%|████      | 10/25 [8:04:55<12:39:15, 3037.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed experiment for split seed 10 (using random seed 60)\n",
      "Median MAE: 0.2042\n",
      "Median Aleatoric Uncertainty: 0.0860\n",
      "Median Epistemic Uncertainty: 0.0638\n",
      "Median Combined Uncertainty: 0.0914\n",
      "--------------------------------------------------\n",
      "Running experiment with split seed 11\n",
      "  Using random seed 61 for split 11\n",
      "  Train: 252862 samples from 23821 events\n",
      "  Validation: 36724 samples from 3403 events\n",
      "  Test: 72648 samples from 6807 events\n",
      "  Training with model seed 42\n",
      "  Seed 42 - MAE: 0.2094\n",
      "  Training with model seed 123\n",
      "  Seed 123 - MAE: 0.2173\n",
      "  Training with model seed 256\n",
      "  Seed 256 - MAE: 0.2111\n",
      "  Training with model seed 789\n",
      "  Seed 789 - MAE: 0.2043\n",
      "  Training with model seed 1024\n",
      "  Seed 1024 - MAE: 0.2025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rRunning experiments 1-25:  44%|████▍     | 11/25 [8:51:31<11:31:27, 2963.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed experiment for split seed 11 (using random seed 61)\n",
      "Median MAE: 0.2094\n",
      "Median Aleatoric Uncertainty: 0.0878\n",
      "Median Epistemic Uncertainty: 0.0689\n",
      "Median Combined Uncertainty: 0.0941\n",
      "--------------------------------------------------\n",
      "Running experiment with split seed 12\n",
      "  Using random seed 62 for split 12\n",
      "  Train: 252502 samples from 23821 events\n",
      "  Validation: 36952 samples from 3403 events\n",
      "  Test: 72780 samples from 6807 events\n",
      "  Training with model seed 42\n",
      "  Seed 42 - MAE: 0.2040\n",
      "  Training with model seed 123\n",
      "  Seed 123 - MAE: 0.1815\n",
      "  Training with model seed 256\n",
      "  Seed 256 - MAE: 0.2195\n",
      "  Training with model seed 789\n",
      "  Seed 789 - MAE: 0.2144\n",
      "  Training with model seed 1024\n",
      "  Seed 1024 - MAE: 0.2007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rRunning experiments 1-25:  48%|████▊     | 12/25 [9:42:07<10:46:50, 2985.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed experiment for split seed 12 (using random seed 62)\n",
      "Median MAE: 0.2040\n",
      "Median Aleatoric Uncertainty: 0.0812\n",
      "Median Epistemic Uncertainty: 0.0702\n",
      "Median Combined Uncertainty: 0.0877\n",
      "--------------------------------------------------\n",
      "Running experiment with split seed 13\n",
      "  Using random seed 63 for split 13\n",
      "  Train: 252929 samples from 23821 events\n",
      "  Validation: 35953 samples from 3403 events\n",
      "  Test: 73352 samples from 6807 events\n",
      "  Training with model seed 42\n",
      "  Seed 42 - MAE: 0.2078\n",
      "  Training with model seed 123\n",
      "  Seed 123 - MAE: 0.1974\n",
      "  Training with model seed 256\n",
      "  Seed 256 - MAE: 0.2228\n",
      "  Training with model seed 789\n",
      "  Seed 789 - MAE: 0.2205\n",
      "  Training with model seed 1024\n",
      "  Seed 1024 - MAE: 0.2087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rRunning experiments 1-25:  52%|█████▏    | 13/25 [10:24:43<9:31:03, 2855.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed experiment for split seed 13 (using random seed 63)\n",
      "Median MAE: 0.2087\n",
      "Median Aleatoric Uncertainty: 0.0872\n",
      "Median Epistemic Uncertainty: 0.0725\n",
      "Median Combined Uncertainty: 0.0940\n",
      "--------------------------------------------------\n",
      "Running experiment with split seed 14\n",
      "  Using random seed 64 for split 14\n",
      "  Train: 254076 samples from 23821 events\n",
      "  Validation: 35854 samples from 3403 events\n",
      "  Test: 72304 samples from 6807 events\n",
      "  Training with model seed 42\n",
      "  Seed 42 - MAE: 0.2182\n",
      "  Training with model seed 123\n",
      "  Seed 123 - MAE: 0.1928\n",
      "  Training with model seed 256\n",
      "  Seed 256 - MAE: 0.2089\n",
      "  Training with model seed 789\n",
      "  Seed 789 - MAE: 0.2220\n",
      "  Training with model seed 1024\n",
      "  Seed 1024 - MAE: 0.2027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rRunning experiments 1-25:  56%|█████▌    | 14/25 [11:09:31<8:34:13, 2804.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed experiment for split seed 14 (using random seed 64)\n",
      "Median MAE: 0.2089\n",
      "Median Aleatoric Uncertainty: 0.0953\n",
      "Median Epistemic Uncertainty: 0.0697\n",
      "Median Combined Uncertainty: 0.1017\n",
      "--------------------------------------------------\n",
      "Running experiment with split seed 15\n",
      "  Using random seed 65 for split 15\n",
      "  Train: 253650 samples from 23821 events\n",
      "  Validation: 37147 samples from 3403 events\n",
      "  Test: 71437 samples from 6807 events\n",
      "  Training with model seed 42\n",
      "  Seed 42 - MAE: 0.1928\n",
      "  Training with model seed 123\n",
      "  Seed 123 - MAE: 0.1986\n",
      "  Training with model seed 256\n",
      "  Seed 256 - MAE: 0.2092\n",
      "  Training with model seed 789\n",
      "  Seed 789 - MAE: 0.2085\n",
      "  Training with model seed 1024\n",
      "  Seed 1024 - MAE: 0.2121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rRunning experiments 1-25:  60%|██████    | 15/25 [11:59:14<7:56:25, 2858.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed experiment for split seed 15 (using random seed 65)\n",
      "Median MAE: 0.2085\n",
      "Median Aleatoric Uncertainty: 0.0924\n",
      "Median Epistemic Uncertainty: 0.0704\n",
      "Median Combined Uncertainty: 0.0988\n",
      "--------------------------------------------------\n",
      "Running experiment with split seed 16\n",
      "  Using random seed 66 for split 16\n",
      "  Train: 253787 samples from 23821 events\n",
      "  Validation: 35015 samples from 3403 events\n",
      "  Test: 73432 samples from 6807 events\n",
      "  Training with model seed 42\n",
      "  Seed 42 - MAE: 0.1923\n",
      "  Training with model seed 123\n",
      "  Seed 123 - MAE: 0.2067\n",
      "  Training with model seed 256\n",
      "  Seed 256 - MAE: 0.2274\n",
      "  Training with model seed 789\n",
      "  Seed 789 - MAE: 0.2133\n",
      "  Training with model seed 1024\n",
      "  Seed 1024 - MAE: 0.1941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rRunning experiments 1-25:  64%|██████▍   | 16/25 [12:49:58<7:17:09, 2914.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed experiment for split seed 16 (using random seed 66)\n",
      "Median MAE: 0.2067\n",
      "Median Aleatoric Uncertainty: 0.0850\n",
      "Median Epistemic Uncertainty: 0.0641\n",
      "Median Combined Uncertainty: 0.0904\n",
      "--------------------------------------------------\n",
      "Running experiment with split seed 17\n",
      "  Using random seed 67 for split 17\n",
      "  Train: 254406 samples from 23821 events\n",
      "  Validation: 36446 samples from 3403 events\n",
      "  Test: 71382 samples from 6807 events\n",
      "  Training with model seed 42\n",
      "  Seed 42 - MAE: 0.2117\n",
      "  Training with model seed 123\n",
      "  Seed 123 - MAE: 0.1955\n",
      "  Training with model seed 256\n",
      "  Seed 256 - MAE: 0.1970\n",
      "  Training with model seed 789\n",
      "  Seed 789 - MAE: 0.2111\n",
      "  Training with model seed 1024\n",
      "  Seed 1024 - MAE: 0.2098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rRunning experiments 1-25:  68%|██████▊   | 17/25 [13:36:13<6:22:59, 2872.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed experiment for split seed 17 (using random seed 67)\n",
      "Median MAE: 0.2098\n",
      "Median Aleatoric Uncertainty: 0.0905\n",
      "Median Epistemic Uncertainty: 0.0657\n",
      "Median Combined Uncertainty: 0.0962\n",
      "--------------------------------------------------\n",
      "Running experiment with split seed 18\n",
      "  Using random seed 68 for split 18\n",
      "  Train: 252418 samples from 23821 events\n",
      "  Validation: 36650 samples from 3403 events\n",
      "  Test: 73166 samples from 6807 events\n",
      "  Training with model seed 42\n",
      "  Seed 42 - MAE: 0.2022\n",
      "  Training with model seed 123\n",
      "  Seed 123 - MAE: 0.2132\n",
      "  Training with model seed 256\n",
      "  Seed 256 - MAE: 0.1984\n",
      "  Training with model seed 789\n",
      "  Seed 789 - MAE: 0.2547\n",
      "  Training with model seed 1024\n",
      "  Seed 1024 - MAE: 0.1880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rRunning experiments 1-25:  72%|███████▏  | 18/25 [14:25:15<5:37:32, 2893.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed experiment for split seed 18 (using random seed 68)\n",
      "Median MAE: 0.2022\n",
      "Median Aleatoric Uncertainty: 0.0849\n",
      "Median Epistemic Uncertainty: 0.0606\n",
      "Median Combined Uncertainty: 0.0901\n",
      "--------------------------------------------------\n",
      "Running experiment with split seed 19\n",
      "  Using random seed 69 for split 19\n",
      "  Train: 253007 samples from 23821 events\n",
      "  Validation: 36823 samples from 3403 events\n",
      "  Test: 72404 samples from 6807 events\n",
      "  Training with model seed 42\n",
      "  Seed 42 - MAE: 0.2075\n",
      "  Training with model seed 123\n",
      "  Seed 123 - MAE: 0.2108\n",
      "  Training with model seed 256\n",
      "  Seed 256 - MAE: 0.2144\n",
      "  Training with model seed 789\n",
      "  Seed 789 - MAE: 0.1969\n",
      "  Training with model seed 1024\n",
      "  Seed 1024 - MAE: 0.2195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rRunning experiments 1-25:  76%|███████▌  | 19/25 [15:11:58<4:46:37, 2866.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed experiment for split seed 19 (using random seed 69)\n",
      "Median MAE: 0.2108\n",
      "Median Aleatoric Uncertainty: 0.0896\n",
      "Median Epistemic Uncertainty: 0.0699\n",
      "Median Combined Uncertainty: 0.0960\n",
      "--------------------------------------------------\n",
      "Running experiment with split seed 20\n",
      "  Using random seed 70 for split 20\n",
      "  Train: 252979 samples from 23821 events\n",
      "  Validation: 36122 samples from 3403 events\n",
      "  Test: 73133 samples from 6807 events\n",
      "  Training with model seed 42\n",
      "  Seed 42 - MAE: 0.1832\n",
      "  Training with model seed 123\n",
      "  Seed 123 - MAE: 0.2039\n",
      "  Training with model seed 256\n",
      "  Seed 256 - MAE: 0.2026\n",
      "  Training with model seed 789\n",
      "  Seed 789 - MAE: 0.2086\n",
      "  Training with model seed 1024\n",
      "  Seed 1024 - MAE: 0.1793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rRunning experiments 1-25:  80%|████████  | 20/25 [16:11:43<4:16:50, 3082.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed experiment for split seed 20 (using random seed 70)\n",
      "Median MAE: 0.2026\n",
      "Median Aleatoric Uncertainty: 0.0793\n",
      "Median Epistemic Uncertainty: 0.0673\n",
      "Median Combined Uncertainty: 0.0850\n",
      "--------------------------------------------------\n",
      "Running experiment with split seed 21\n",
      "  Using random seed 71 for split 21\n",
      "  Train: 253872 samples from 23821 events\n",
      "  Validation: 35580 samples from 3403 events\n",
      "  Test: 72782 samples from 6807 events\n",
      "  Training with model seed 42\n",
      "  Seed 42 - MAE: 0.2025\n",
      "  Training with model seed 123\n",
      "  Seed 123 - MAE: 0.1828\n",
      "  Training with model seed 256\n",
      "  Seed 256 - MAE: 0.2172\n",
      "  Training with model seed 789\n",
      "  Seed 789 - MAE: 0.2207\n",
      "  Training with model seed 1024\n",
      "  Seed 1024 - MAE: 0.2257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rRunning experiments 1-25:  84%|████████▍ | 21/25 [16:59:33<3:21:13, 3018.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed experiment for split seed 21 (using random seed 71)\n",
      "Median MAE: 0.2172\n",
      "Median Aleatoric Uncertainty: 0.1047\n",
      "Median Epistemic Uncertainty: 0.0745\n",
      "Median Combined Uncertainty: 0.1120\n",
      "--------------------------------------------------\n",
      "Running experiment with split seed 22\n",
      "  Using random seed 72 for split 22\n",
      "  Train: 252877 samples from 23821 events\n",
      "  Validation: 35609 samples from 3403 events\n",
      "  Test: 73748 samples from 6807 events\n",
      "  Training with model seed 42\n",
      "  Seed 42 - MAE: 0.1838\n",
      "  Training with model seed 123\n",
      "  Seed 123 - MAE: 0.2036\n",
      "  Training with model seed 256\n",
      "  Seed 256 - MAE: 0.2188\n",
      "  Training with model seed 789\n",
      "  Seed 789 - MAE: 0.2113\n",
      "  Training with model seed 1024\n",
      "  Seed 1024 - MAE: 0.2155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rRunning experiments 1-25:  88%|████████▊ | 22/25 [17:46:28<2:27:51, 2957.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed experiment for split seed 22 (using random seed 72)\n",
      "Median MAE: 0.2113\n",
      "Median Aleatoric Uncertainty: 0.1019\n",
      "Median Epistemic Uncertainty: 0.0687\n",
      "Median Combined Uncertainty: 0.1078\n",
      "--------------------------------------------------\n",
      "Running experiment with split seed 23\n",
      "  Using random seed 73 for split 23\n",
      "  Train: 253103 samples from 23821 events\n",
      "  Validation: 36794 samples from 3403 events\n",
      "  Test: 72337 samples from 6807 events\n",
      "  Training with model seed 42\n",
      "  Seed 42 - MAE: 0.2184\n",
      "  Training with model seed 123\n",
      "  Seed 123 - MAE: 0.1887\n",
      "  Training with model seed 256\n",
      "  Seed 256 - MAE: 0.1966\n",
      "  Training with model seed 789\n",
      "  Seed 789 - MAE: 0.2254\n",
      "  Training with model seed 1024\n",
      "  Seed 1024 - MAE: 0.1956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rRunning experiments 1-25:  92%|█████████▏| 23/25 [18:36:24<1:38:57, 2968.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed experiment for split seed 23 (using random seed 73)\n",
      "Median MAE: 0.1966\n",
      "Median Aleatoric Uncertainty: 0.0796\n",
      "Median Epistemic Uncertainty: 0.0634\n",
      "Median Combined Uncertainty: 0.0849\n",
      "--------------------------------------------------\n",
      "Running experiment with split seed 24\n",
      "  Using random seed 74 for split 24\n",
      "  Train: 251920 samples from 23821 events\n",
      "  Validation: 36197 samples from 3403 events\n",
      "  Test: 74117 samples from 6807 events\n",
      "  Training with model seed 42\n",
      "  Seed 42 - MAE: 0.1910\n",
      "  Training with model seed 123\n",
      "  Seed 123 - MAE: 0.2117\n",
      "  Training with model seed 256\n",
      "  Seed 256 - MAE: 0.2073\n",
      "  Training with model seed 789\n",
      "  Seed 789 - MAE: 0.1920\n",
      "  Training with model seed 1024\n",
      "  Seed 1024 - MAE: 0.2102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rRunning experiments 1-25:  96%|█████████▌| 24/25 [19:30:54<50:59, 3059.22s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed experiment for split seed 24 (using random seed 74)\n",
      "Median MAE: 0.2073\n",
      "Median Aleatoric Uncertainty: 0.0928\n",
      "Median Epistemic Uncertainty: 0.0706\n",
      "Median Combined Uncertainty: 0.0991\n",
      "--------------------------------------------------\n",
      "Running experiment with split seed 25\n",
      "  Using random seed 75 for split 25\n",
      "  Train: 255036 samples from 23821 events\n",
      "  Validation: 35318 samples from 3403 events\n",
      "  Test: 71880 samples from 6807 events\n",
      "  Training with model seed 42\n",
      "  Seed 42 - MAE: 0.2042\n",
      "  Training with model seed 123\n",
      "  Seed 123 - MAE: 0.1981\n",
      "  Training with model seed 256\n",
      "  Seed 256 - MAE: 0.1935\n",
      "  Training with model seed 789\n",
      "  Seed 789 - MAE: 0.2130\n",
      "  Training with model seed 1024\n",
      "  Seed 1024 - MAE: 0.2056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running experiments 1-25: 100%|██████████| 25/25 [20:23:25<00:00, 2936.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed experiment for split seed 25 (using random seed 75)\n",
      "Median MAE: 0.2042\n",
      "Median Aleatoric Uncertainty: 0.0881\n",
      "Median Epistemic Uncertainty: 0.0647\n",
      "Median Combined Uncertainty: 0.0937\n",
      "--------------------------------------------------\n",
      "\n",
      "Total execution time: 1223.42 minutes\n",
      "\n",
      "INSTANCE Experiment batch 1-25 completed. Results saved in:\n",
      "- /content/drive/My Drive/2023-2024/UCL MSc in DSML/Term 3/MSc Project/Code/INSTANCE_Event_Based/experiment_results/results_1_to_25.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#------------------------------------------------------------------------------\n",
    "# Main Execution\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Define model initialization seeds (these stay fixed across all experiments)\n",
    "    model_seeds = [42, 123, 256, 789, 1024]  # 5 different model initializations\n",
    "\n",
    "    # Define the specific split seeds for this notebook\n",
    "    split_seeds = list(range(START_SEED, END_SEED + 1))\n",
    "\n",
    "    # Define results file for this range of experiments\n",
    "    results_file = os.path.join(output_dir, f\"results_{START_SEED}_to_{END_SEED}.json\")\n",
    "\n",
    "    # Run experiments with the specified split seeds\n",
    "    all_results = []\n",
    "\n",
    "    print(f\"Starting INSTANCE Event-Based Splitting Experiments {START_SEED}-{END_SEED}\")\n",
    "    print(f\"Expected: INSTANCE (avg 10.64 seismograms/event) should show MORE pronounced\")\n",
    "    print(f\"differences than STEAD (avg 2.14 seismograms/event) between splitting methods\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    for i, split_seed in enumerate(tqdm(split_seeds, desc=f\"Running experiments {START_SEED}-{END_SEED}\")):\n",
    "        # Calculate the global run ID (to maintain consistent naming with the original code)\n",
    "        global_run_id = split_seed  # This keeps the same run_id as in the original code\n",
    "\n",
    "        # Run experiment for this split\n",
    "        result = run_experiment(split_seed, model_seeds, global_run_id)\n",
    "        all_results.append(result)\n",
    "\n",
    "        # Save results after each split\n",
    "        with open(results_file, 'w') as f:\n",
    "            # Convert numpy arrays to Python lists before serialization\n",
    "            serializable_results = numpy_to_python(all_results)\n",
    "            json.dump(serializable_results, f, indent=4)\n",
    "\n",
    "        print(f\"Completed experiment for split seed {split_seed} (using random seed {split_seed + RANDOM_SEED_OFFSET})\")\n",
    "        print(f\"Median MAE: {result['median_mae']:.4f}\")\n",
    "        print(f\"Median Aleatoric Uncertainty: {result['median_aleatoric_uncertainty']:.4f}\")\n",
    "        print(f\"Median Epistemic Uncertainty: {result['median_epistemic_uncertainty']:.4f}\")\n",
    "        print(f\"Median Combined Uncertainty: {result['median_combined_uncertainty']:.4f}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "    # End timing\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"\\nTotal execution time: {elapsed_time/60:.2f} minutes\")\n",
    "\n",
    "    print(f\"\\nINSTANCE Experiment batch {START_SEED}-{END_SEED} completed. Results saved in:\")\n",
    "    print(f\"- {results_file}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "name": "",
   "version": ""
  },
  "kernelspec": {
   "display_name": "comp0197-cw1-pt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
